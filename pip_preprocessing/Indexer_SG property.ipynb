{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install comtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app/RB/.local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (4.0.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import uuid\n",
    "from statistics import mode\n",
    "from nltk.corpus import stopwords\n",
    "from pdf2txt import convert_pdf\n",
    "# !pip install tika\n",
    "import tika\n",
    "from definitions_v3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsRE_heading=re.compile('(?:\\s*\\([a-z]{1,3}\\)|[A-Z]{1}\\s+[a-zA-Z0-9_\\s]{5})')\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "y_cordinate_Re=re.compile('top:(\\d{1,5})px')\n",
    "height_re=re.compile('height:(\\d{1,5})px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_underline(positions,y_cord_text):\n",
    "    positions=[i for i in positions if y_cord_text<=i< y_cord_text+16]\n",
    "    if positions:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_no(soup):\n",
    "    total_items = int(soup.find('span', id='NewReleases_total').text)\n",
    "    items_per_page = int(soup.find('span', id='NewReleases_end').text)\n",
    "    return round(total_items/items_per_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "\n",
    "# print(len(list(extract_pages('test/Chubb16-250-1019 Chubb EBM Business Pack Product Disclosure Statement (PDS) and Policy Wording.pdf'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_underlines(soup):\n",
    "    positions=[]\n",
    "    for span in soup.find_all('span'):\n",
    "        y_cord_list=y_cordinate_Re.findall(str(span))\n",
    "        if y_cord_list:\n",
    "            y_cord=int(y_cord_list[0])\n",
    "        else:\n",
    "            continue\n",
    "        style=\"position:absolute; border: black 1px solid\" in str(span)\n",
    "        height_px_li=height_re.findall(str(span))\n",
    "        if height_px_li:\n",
    "            height_px=height_px_li[0]\n",
    "        else:\n",
    "            continue\n",
    "        height=int(height_px)<15\n",
    "        if all([style,height]):\n",
    "            positions.append(y_cord)\n",
    "    return list(set(positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_extract(text_list,language):\n",
    "    ext_flag=False\n",
    "    if language=='english':\n",
    "        ext_lis=['extension']\n",
    "    else:\n",
    "        ext_lis=['extensión','extensiones']\n",
    "   \n",
    "    ext_count=0\n",
    "    position_list=[]\n",
    "    position=0\n",
    "    for text in text_list:\n",
    "        # if any two of 'exclusion ,condition or extension is present in the text, that text is omitted from the logic'\n",
    "        bool_list=['condition' in text.lower(),'exclusion' in text.lower(),'extension' in text.lower()]\n",
    "        if sum(bool_list)>=2:\n",
    "            continue\n",
    "        for i in ext_lis:\n",
    "            for match in re.finditer(i, text.lower()):\n",
    "                position_list.append(position+match.start())               \n",
    "                ext_count+=1\n",
    "        position+=len(text)\n",
    "    if ext_count>=1:\n",
    "        ext_flag=True\n",
    "    return(ext_flag,ext_count,position_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excl_extract(text_list,language):\n",
    "    exclusion_flag=False\n",
    "    if language=='english':\n",
    "        excl_lis=['exclud','not cover','except','does not mean','not includ','exclusion']\n",
    "    else:\n",
    "        excl_lis=['excepto','excepción','no in cluido','exclusión','excluidos','excluirlo','excluyendo','exclusiones','exclusion','excluyen','excluyentes']\n",
    "   \n",
    "    exclusion_count=0\n",
    "    position_list=[]\n",
    "    position=0\n",
    "    for text in text_list:\n",
    "        # if any two of 'exclusion ,condition or extension is present in the text, that text is omitted from the logic'\n",
    "        bool_list=['condition' in text.lower(),'exclusion' in text.lower(),'extension' in text.lower()]\n",
    "        if sum(bool_list)>=2:\n",
    "            continue\n",
    "        for i in excl_lis:\n",
    "            for match in re.finditer(i, text.lower()):\n",
    "                position_list.append(position+match.start())               \n",
    "                exclusion_count+=1\n",
    "        position+=len(text)\n",
    "    if exclusion_count>=1:\n",
    "        exclusion_flag=True\n",
    "    return(exclusion_flag,exclusion_count,position_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_extract(text_list,language):\n",
    "    cond_flag=False\n",
    "    if language=='english':\n",
    "        cond_lis=['condition']\n",
    "    else:\n",
    "        cond_lis=['condición','condiciones','condicionado']\n",
    "   \n",
    "    cond_count=0\n",
    "    position_list=[]\n",
    "    position=0\n",
    "    for text in text_list:\n",
    "        # if any two of 'exclusion ,condition or extension is present in the text, that text is omitted from the logic'\n",
    "        bool_list=['condition' in text.lower(),'exclusion' in text.lower(),'extension' in text.lower()]\n",
    "        if sum(bool_list)>=2:\n",
    "            continue\n",
    "        for i in cond_lis:\n",
    "            for match in re.finditer(i, text.lower()):\n",
    "                position_list.append(position+match.start())               \n",
    "                cond_count+=1\n",
    "        position+=len(text)\n",
    "    if cond_count>=1:\n",
    "        cond_flag=True\n",
    "    return(cond_flag,cond_count,position_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_extraction(soup):\n",
    "    fontsizes=[]\n",
    "    for divs in soup.findAll('div'):\n",
    "        for j in divs.find_all('span'):\n",
    "            ext_size=re.findall(r'font-size:(.*)px\">',str(j))\n",
    "            if ext_size:\n",
    "                fontsizes.append(int(ext_size[0]))\n",
    "    return(fontsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_check(word,text,language):\n",
    "    if language=='spanish':\n",
    "        stop_words = list(set(stopwords.words('spanish')))\n",
    "    else:\n",
    "        stop_words = list(set(stopwords.words('english')))\n",
    "        transition=\"although  instead  whereas  despite  conversely  otherwise  however moreover  likewise  comparatively  correspondingly  similarly  furthermore  additionallyver  rather  nevertheless  nonetheless  regardless  notwithstanding consequently  therefore  thereupon  forthwith  accordingly  henceforth\"\n",
    "        transition_words=transition.split()\n",
    "        transition_words\n",
    "        stop_words.extend(transition_words)\n",
    "\n",
    "    if exclusion_check(text,language):\n",
    "        return True\n",
    "    if word.lower() in stop_words:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclusion_check(text,language):\n",
    "    if language=='spanish':\n",
    "        exclusion_bag=['excepto','excepción','no in cluido','exclusión','excluidos','excluirlo','excluyendo',' excluyen','exclusiones','exclusiones','exclusion','excluyentes']\n",
    "    else:\n",
    "        exclusion_bag=['exclusion','excluded','not covered','will not cover','will not pay']\n",
    "    for word in exclusion_bag:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criteria_check(text,language):\n",
    "    if language=='spanish':\n",
    "        exclusion_bag=['condición','condiciones','condicionado']\n",
    "    else:\n",
    "        exclusion_bag=['condition','conditions']\n",
    "    for word in exclusion_bag:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_check(text,language):\n",
    "    if language=='english':\n",
    "        ext_bag=['extension']\n",
    "    else:\n",
    "        ext_bag=['extensión','extensiones']\n",
    "    for word in ext_bag:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=re.compile('.*\\d{1,3}.*(?:\\-|\\.|–)')\n",
    "def clean(text):\n",
    "    text=text.replace('\\n','').replace('\\t',' ')\n",
    "    text=start.sub('',text).strip()\n",
    "    \n",
    "\n",
    "    return(text)\n",
    "def clean_pharses(phrases):\n",
    "    phrases=[clean(i) for i in phrases if len(i)> 3]\n",
    "    phrases=list(set(phrases))\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_index(path,subdir,language,country):\n",
    "    pointsRE_heading=re.compile('(?:\\s*\\([a-z]{1,3}\\)|(?<![A-z])[A-Z]{1}\\s+[a-zA-Z0-9_\\s]{5})')\n",
    "    pageNumRE=re.compile('Page\\s*(\\d{1,3})',re.IGNORECASE)\n",
    "    neglect_def=['policy','insured','schedule']\n",
    "    local_indexed={}\n",
    "    previous_span=''\n",
    "    bold_phrases_indexed={}\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.pdf'):\n",
    "            print(file)\n",
    "            global file_count\n",
    "            file_count+=1\n",
    "            \n",
    "            print(\"COUNT\",file_count)\n",
    "            try:\n",
    "                pg_no=len(list(extract_pages(os.path.join(path,file))))\n",
    "            except:\n",
    "                pg_no=0\n",
    "            try:\n",
    "                html=convert_pdf(os.path.join(path,file),'html')\n",
    "            except:\n",
    "                continue\n",
    "            soup = BeautifulSoup(html, 'html5lib')\n",
    "            underline_positions=get_underlines(soup)\n",
    "            try:\n",
    "                fontsizes=font_extraction(soup)\n",
    "                file_font_size_mode=mode(fontsizes)\n",
    "            except:\n",
    "                file_font_size_mode=8\n",
    "                \n",
    "            text_para,text_plain_para='',''\n",
    "            text_lis,text_plain_lis,bold_lis,page_list,=[],[],[],[]\n",
    "            bold=False\n",
    "            sub_page_def_list=[]\n",
    "            try:\n",
    "                definitions=def_extraction(os.path.join(path,file))\n",
    "            except:\n",
    "                continue\n",
    "            definitions={key:value for key,value in definitions.items() if key.lower().strip() not in neglect_def}\n",
    "            def_terms=list(definitions.keys())\n",
    "#             print(len(def_terms),'LEN DEFINITIONS')\n",
    "#             print(definitions)\n",
    "            definition_text=''\n",
    "            header_match_object=(0,'',False)\n",
    "            cond_header_match_object=(0,'',False)\n",
    "            ext_header_match_object=(0,'',False)\n",
    "            second_category=False\n",
    "            head_found=False\n",
    "            def_flag=False\n",
    "            cond_head_found=False\n",
    "            ext_head_found=False\n",
    "            single_page_head_found=False\n",
    "            condition_text=''\n",
    "            ext_text=''\n",
    "            excl_text=''\n",
    "            previous_pg_num=[]\n",
    "            def_in_page=[]\n",
    "            cond_single_page_head_found=False\n",
    "            ext_single_page_head_found=False\n",
    "            \n",
    "            font_size=file_font_size_mode\n",
    "\n",
    "            for divs in soup.findAll('div'):\n",
    "                div_text_list=[span.text for span in divs.find_all('span') ]\n",
    "                page_str=str(divs.find_all('a'))\n",
    "                page_num_results=pageNumRE.findall(page_str)\n",
    "                if page_num_results:\n",
    "                    pagenum=page_num_results[0]\n",
    "#                     print(pagenum)\n",
    "                    if pagenum!=previous_pg_num:\n",
    "                        sub_definitions_in_page=[]\n",
    "                    previous_pg_num=pagenum\n",
    "#                     definition_text=''\n",
    "                    \n",
    "                    #only for pdfs\n",
    "                    if(int(pagenum) in [1,2]) and 'Wording' in file and pg_no >20:\n",
    "#                     print('Continued on wording 2')\n",
    "                        continue\n",
    "\n",
    "                    if text_lis:\n",
    "                        text_lis=text_lis[:-1]\n",
    "                        text_para=''.join(text_lis)\n",
    "                        text_plain_lis=text_plain_lis[:-1]\n",
    "                        text_plain_para=''.join(text_plain_lis)\n",
    "                        if(len(re.findall('\\.',text_para))>(len(text_para)/3) or (len(re.findall('\\d',text_para))>80 and int(pagenum)<4 and  pg_no>20 and 'content' in text_para.lower())) :\n",
    "                            print('PASS')\n",
    "                            print(text_plain_para)\n",
    "                            text_para,text_plain_para=' ',' '\n",
    "                            text_lis,text_plain_lis=[],[]\n",
    "                            single_page_head_found=False\n",
    "                            head_found=False\n",
    "                            cond_head_found=False\n",
    "                            ext_head_found=False\n",
    "                            continue\n",
    "                        \n",
    "                        else:\n",
    "                            bold_lis=clean_pharses(bold_lis)\n",
    "                            pagenum=int(pagenum)-1\n",
    "                            excl_flag,excl_count,excl_pos_lis=excl_extract(text_plain_lis,language)\n",
    "                            cond_flag,cond_count,cond_pos_lis=cond_extract(text_plain_lis,language)\n",
    "                            ext_flag,ext_count,ext_pos_lis=ext_extract(text_plain_lis,language)\n",
    "                            if int(pagenum)==1:\n",
    "                                if head_found or single_page_head_found or excl_count>0:\n",
    "#                                     print(pagenum,True,'!!!')\n",
    "                                    excl_flag=True\n",
    "                                else:\n",
    "                                    excl_flag=False\n",
    "                            else:\n",
    "                                if head_found or single_page_head_found:\n",
    "#                                     print(pagenum,True,'!!!',excl_count)\n",
    "                                    excl_flag=True\n",
    "#                                     print(excl_flag,'EXCL')\n",
    "#                                 else:\n",
    "#                                     print(pagenum,excl_flag,'\\n')\n",
    "# #                             print(excl_text)\n",
    "#                             print(condition_text)\n",
    "                            if cond_head_found or cond_single_page_head_found or cond_count>0:\n",
    "                                cond_flag=True\n",
    "#                                 print('COND','TRUE')\n",
    "                            else:\n",
    "#                                 print('COND','FALSE')\n",
    "                                cond_flag=False\n",
    "    \n",
    "                            if ext_head_found or ext_single_page_head_found or ext_count>0:\n",
    "                                ext_flag=True\n",
    "#                                 print('EXT','TRUE',pagenum)\n",
    "                            else:\n",
    "#                                 print('EXT','FALSE',pagenum)\n",
    "                                ext_flag=False\n",
    "#                             def_in_page=[{'name':k,'text':v[0] for k,v in definitions.items() if v[1]=pagenum}]\n",
    "                            for term,defs in definitions.items():\n",
    "#                                 print(defs[1])\n",
    "                                if defs[1]==pagenum:  ###defs[1] is the pagenumber\n",
    "                                    definition_text=definition_text+'          '+term+' '+defs[0]\n",
    "                                    def_in_page.append({'name':term,'text':defs[0]})\n",
    "#                                     def_in_page{'name':}\n",
    "#                             print(definition_text)\n",
    "                            if definition_text:\n",
    "                                def_flag=True\n",
    "                            \n",
    "                            if def_flag:\n",
    "                                def_search_flag=True\n",
    "#                                 print('DEF','TRUE')\n",
    "                            else:\n",
    "#                                 print('DEF', 'FALSE')\n",
    "                                def_search_flag=False   \n",
    "                            \n",
    "                            if pg_no>2:\n",
    "                                endorsements=False\n",
    "                            else:\n",
    "                                endorsements=True\n",
    "#                             print(endorsements,'ENDORSEMENTS!!!')\n",
    "                            if text_para in local_indexed.keys():\n",
    "                                text_para=text_para+' '\n",
    "                            \n",
    "                            local_indexed[text_para]=(file,pagenum,bold_lis,text_plain_para,excl_flag,excl_count,excl_pos_lis,subdir,sub_page_def_list,country,language,definition_text,def_search_flag,endorsements,excl_text,condition_text,cond_flag,cond_count,cond_pos_lis,def_in_page,ext_text,ext_flag,ext_count,ext_pos_lis)\n",
    "#                             print(sub_page_def_list,'DEF LIST!!!!!1')\n",
    "                            sub_page_def_list=[]\n",
    "                            page_list.append(pagenum)\n",
    "                            text_para,text_plain_para='',''\n",
    "                            text_lis,text_plain_lis,bold_lis=[],[],[]\n",
    "                            definition_text=''\n",
    "                            cond_single_page_head_found=False\n",
    "                            ext_single_page_head_found=False\n",
    "                            condition_text=''\n",
    "                            ext_text=''\n",
    "                            excl_text=''\n",
    "                            single_page_head_found=False\n",
    "                            def_in_page=[]\n",
    "                            def_flag=False\n",
    "                for span in divs.find_all('span'):\n",
    "\n",
    "                    bold=False\n",
    "                    upper=False\n",
    "                    bullet=False\n",
    "                    def_flag=False\n",
    "                    span_position=div_text_list.index(span.text)\n",
    "                    \n",
    "                    if \"Bold\" in str(span) or 'CIDFont+F3' in str(span):\n",
    "                        bold_lis.append(span.text)\n",
    "                        bold=True\n",
    "                    if span.text.isupper():\n",
    "                        upper=True\n",
    "                    font_family_match=re.findall(r\"font-family: b'(.*)';\",str(span))\n",
    "                    if font_family_match:\n",
    "                        font_family=font_family_match[0]\n",
    "                    else:\n",
    "                        font_family=''\n",
    "#                     print(font_family)\n",
    "                    font_size_match=re.findall(r'font-size:(.*)px\">',str(span))\n",
    "                    if font_size_match:\n",
    "                        font_size=int(font_size_match[0])\n",
    "                    if pointsRE_heading.findall(span.text):\n",
    "                        bullet=True\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "                    y_cord_list=y_cordinate_Re.findall(str(divs))\n",
    "                    if y_cord_list:\n",
    "                        y_cord=int(y_cord_list[0])\n",
    "                    underlined_text=check_underline(underline_positions,y_cord)\n",
    "                    if span.text.split('\\n')[0]!='' and span.text.split('\\n')[0]!=' ':\n",
    "                        head_check_text=span.text.split('\\n')[0]\n",
    "                    elif len(span.text.split('\\n'))>1:\n",
    "                        head_check_text=span.text.split('\\n')[1]\n",
    "                    else:\n",
    "                        head_check_text=''\n",
    "##############################3  \n",
    "                    if str(previous_span).endswith('<br/></span>'):\n",
    "                        span_position=0\n",
    "                    ##################INSERT FUNCTION####################z\n",
    "                    #EXCLUSION \n",
    "                    if  span_position==0 and (bold or font_size>= file_font_size_mode +2 ) and (font_size> file_font_size_mode or upper) and 5<len(head_check_text.strip())<80:                    \n",
    "                        if exclusion_check(head_check_text,language) and not head_found: \n",
    "                            head_found=True\n",
    "                            header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "                            First_category=True\n",
    "                            second_category=False\n",
    "                            single_page_head_found=True\n",
    "#                             print('FOUND Heading for exclusion ...',span.text)\n",
    "                        \n",
    "                    \n",
    "                        elif ((font_size,font_family,bold,upper,bullet)==header_match_object  or font_size>header_match_object[0] ) and head_found and not exclusion_check(head_check_text,language):\n",
    "                            head_found=False\n",
    "                            single_page_head_found=True\n",
    "#                             print('FOUND Closure for exclusion ...',span.text)\n",
    "#                     if 'CLAIMS CONDITIONS' in span.text:\n",
    "#                         print ('^^^^^^^',(font_size,font_family,bold,upper,bullet),header_match_object, font_size>header_match_object[0] , head_found , not exclusion_check(head_check_text,language))\n",
    "#                         print(pointsRE_heading.findall(span.text))\n",
    "                    words_title=[word.istitle() for word in head_check_text.split() if stopword_check(word,head_check_text,language) and not word.isdigit() ]\n",
    "                    if span_position==0 and all(words_title) and head_check_text.strip() not in definitions and  (len(words_title) >1 or underlined_text )and 5<len(head_check_text.strip())<80 :\n",
    "#                         print('MMMMMMMMARARARA',span.text)\n",
    "\n",
    "                        if exclusion_check(head_check_text,language) and  not head_found:\n",
    "                            head_found=True\n",
    "                            second_category=True\n",
    "                            First_category=False\n",
    "                            single_page_head_found=True\n",
    "                            header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "#                             print(\"FOUND heading type2 ....\",span.text)\n",
    "                        elif head_found and not exclusion_check(head_check_text,language) and second_category and ((font_size,font_family,bold,upper,bullet)==header_match_object or font_size > header_match_object[0] ) :\n",
    "                            head_found=False\n",
    "                            second_category=False\n",
    "                            single_page_head_found=True\n",
    "#                             print('FOUND closure type 2',span.text)\n",
    "                    if head_found:\n",
    "                        excl_text=excl_text+' '+span.text     \n",
    "                     \n",
    "                    #CONDITIONS\n",
    "#                     if 'Condition' in span.text:\n",
    "# #                         print('text:',str(span.text),'head check',head_check_text,'length of head check',len(head_check_text))\n",
    "# #                         print(span_position==0,(bold or font_size>= file_font_size_mode +2 ), (font_size> file_font_size_mode or upper), 5<len(head_check_text.strip())<80)\n",
    "# #                         print(font_size,file_font_size_mode,cond_head_found,criteria_check(head_check_text,language))\n",
    "                    if  span_position==0 and (bold or font_size>= file_font_size_mode +2 ) and (font_size> file_font_size_mode or upper) and 5<len(head_check_text.strip())<80:                    \n",
    "                        if criteria_check(head_check_text,language) and not cond_head_found: \n",
    "                            cond_head_found=True\n",
    "                            cond_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "                            cond_First_category=True\n",
    "                            cond_second_category=False\n",
    "                            cond_single_page_head_found=True\n",
    "#                             print('FOUND Heading for condition...',span.text)\n",
    "                    \n",
    "                        elif ((font_size,font_family,bold,upper,bullet)==cond_header_match_object or font_size>cond_header_match_object[0] ) and not criteria_check(head_check_text,language)  and cond_head_found:\n",
    "                            cond_head_found=False\n",
    "                            cond_single_page_head_found=True\n",
    "#                             print('FOUND Closure for condition ...',span.text)\n",
    "                \n",
    "                    \n",
    "                    cond_words_title=[word.istitle() for word in head_check_text.split() if stopword_check(word,head_check_text,language) and not word.isdigit() ]\n",
    "                    if span_position==0 and all(cond_words_title) and head_check_text.strip() not in definitions and  (len(words_title) >1 or underlined_text )and 5<len(head_check_text.strip())<80 :\n",
    "#                         print('MMMMMMMMARARARA',span.text)\n",
    "\n",
    "                        if criteria_check(head_check_text,language) and  not cond_head_found:\n",
    "                            cond_head_found=True\n",
    "                            cond_second_category=True\n",
    "                            cond_First_category=False\n",
    "                            cond_single_page_head_found=True\n",
    "                            cond_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "#                             print(\"FOUND heading type2 ....\",span.text)\n",
    "                        elif cond_head_found and not criteria_check(head_check_text,language) and cond_second_category and ((font_size,font_family,bold,upper,bullet)==cond_header_match_object or font_size > cond_header_match_object[0] ) :\n",
    "                            cond_head_found=False\n",
    "                            cond_second_category=False\n",
    "                            cond_single_page_head_found=True\n",
    "#                             print('FOUND closure type 2',span.text)\n",
    "\n",
    "                    if cond_head_found==True:\n",
    "                        condition_text=condition_text+' '+span.text\n",
    "                            \n",
    "                    \n",
    "                    #####EXTENSIONS\n",
    "                    #CONDITIONS\n",
    "#                     if 'Extension' in span.text:\n",
    "#                         print(span.text)\n",
    "#                         print('text:',str(span.text),'head check',head_check_text,'length of head check',len(head_check_text))\n",
    "#                         print(span_position==0,(bold or font_size>= file_font_size_mode +2 ), (font_size> file_font_size_mode or upper), 5<len(head_check_text.strip())<80)\n",
    "#                         print(font_size,file_font_size_mode,cond_head_found,criteria_check(head_check_text,language))\n",
    "                    if  span_position==0 and (bold or font_size>= file_font_size_mode +2 ) and (font_size> file_font_size_mode or upper) and 5<len(head_check_text.strip())<80:                    \n",
    "                        if ext_check(head_check_text,language) and not ext_head_found: \n",
    "                            ext_head_found=True\n",
    "                            ext_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "                            ext_First_category=True\n",
    "                            ext_second_category=False\n",
    "                            ext_single_page_head_found=True\n",
    "#                             print('FOUND Heading for ext...',span.text)\n",
    "                    \n",
    "                        elif ((font_size,font_family,bold,upper,bullet)==ext_header_match_object or font_size>ext_header_match_object[0] ) and not ext_check(head_check_text,language)  and ext_head_found:\n",
    "                            ext_head_found=False\n",
    "                            ext_single_page_head_found=True\n",
    "#                             print('FOUND Closure for ext ...',span.text)\n",
    "                \n",
    "                    \n",
    "                    ext_words_title=[word.istitle() for word in head_check_text.split() if stopword_check(word,head_check_text,language) and not word.isdigit() ]\n",
    "                    if span_position==0 and all(ext_words_title) and head_check_text.strip() not in definitions and  (len(words_title) >1 or underlined_text )and 5<len(head_check_text.strip())<80 :\n",
    "#                         print('MMMMMMMMARARARA',span.text)\n",
    "\n",
    "                        if ext_check(head_check_text,language) and  not ext_head_found:\n",
    "                            ext_head_found=True\n",
    "                            ext_second_category=True\n",
    "                            ext_First_category=False\n",
    "                            ext_single_page_head_found=True\n",
    "                            ext_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "#                             print(\"FOUND heading type2 ext....\",span.text)\n",
    "                        elif ext_head_found and not ext_check(head_check_text,language) and ext_second_category and ((font_size,font_family,bold,upper,bullet)==ext_header_match_object or font_size > ext_header_match_object[0] ) :\n",
    "                            ext_head_found=False\n",
    "                            ext_second_category=False\n",
    "                            ext_single_page_head_found=True\n",
    "#                             print('FOUND closure type 2 ext',span.text)\n",
    "# \n",
    "                    if ext_head_found==True:\n",
    "                        ext_text=ext_text+' '+span.text\n",
    "                            \n",
    "    #                     else:\n",
    "###############################             \n",
    "                        \n",
    "                    if font_size_match:\n",
    "                        if font_size<=file_font_size_mode-1:\n",
    "                            text_lis.append(' ')\n",
    "                    text=span.text.replace('\\n',' ')\n",
    "                    text_plain=text.replace('\\n',' ')\n",
    "                    for term in def_terms:\n",
    "                        if term.lower().strip() in text.lower() and definitions[term][0].strip() not in text and term not in sub_definitions_in_page:\n",
    "#                             def_page.append(definitions[term])\n",
    "#                             print(pagenum)\n",
    "                            src_str  = re.compile(re.escape(term), re.IGNORECASE)\n",
    "                            text=src_str.sub('###{}@@{}%%%'.format(term,definitions[term][0]),text)\n",
    "#                             print(text,'\\n',term,'TERM!!!!@#$%^&*&^%#$%^&')\n",
    "                            sub_definitions_in_page.append(term)\n",
    "                            sub_page_def_list.append({'name':term,'text':definitions[term][0]})\n",
    "#                             print(definitions_in_page)\n",
    "                            break\n",
    "#                     print(definitions_in_page)\n",
    "\n",
    "                    \n",
    "                    text_lis.append(text)\n",
    "                    text_plain_lis.append(text_plain)\n",
    "                    previous_span=span\n",
    "                    \n",
    "\n",
    "            if text_lis:\n",
    "                if(int(pagenum) in [1,2]) and 'Wording' in file and pg_no >20:\n",
    "#                     print('Continued on wording 2')\n",
    "                    continue\n",
    "\n",
    "                text_lis=text_lis[:-1]\n",
    "                text_para=''.join(text_lis)\n",
    "                text_plain_lis=text_plain_lis[:-1]\n",
    "                text_plain_para=''.join(text_plain_lis)\n",
    "                if(len(re.findall('\\.',text_para))>(len(text_para)/3) or (len(re.findall('\\d',text_para))>80 and int(pagenum)<4 and pg_no>20 and 'content' in text_para.lower())) :\n",
    "                    print('PASS')\n",
    "                    print(text_plain_para)\n",
    "                    text_para,text_plain_para=' ',' '\n",
    "                    text_lis,text_plain_lis=[],[]\n",
    "                    single_page_head_found=False\n",
    "                    head_found=False\n",
    "                    cond_head_found=False\n",
    "                    ext_head_found=False\n",
    "                    continue\n",
    "                else:\n",
    "                    bold_lis=clean_pharses(bold_lis)\n",
    "                    if pagenum in page_list and pagenum!='1':\n",
    "                        pagenum=int(pagenum)+1\n",
    "                    excl_flag,excl_count,excl_pos_lis=excl_extract(text_plain_lis,language)\n",
    "                    cond_flag,cond_count,cond_pos_lis=cond_extract(text_plain_lis,language)\n",
    "                    ext_flag,ext_count,ext_pos_lis=ext_extract(text_plain_lis,language)\n",
    "                    if int(pagenum)==1:\n",
    "                        if head_found or single_page_head_found or excl_count>0:\n",
    "#                             print(pagenum,True,'!!!',excl_count)\n",
    "                            excl_flag=True\n",
    "                        else:\n",
    "                            excl_flag=False\n",
    "                    else:\n",
    "                        if head_found or single_page_head_found:\n",
    "#                             print(pagenum,True,'!!!')\n",
    "                            excl_flag=True\n",
    "#                             print(excl_flag,'EXCL')\n",
    "                        \n",
    "                    #####################\n",
    "                    if cond_head_found or cond_single_page_head_found or cond_count>0:\n",
    "                        cond_flag=True\n",
    "#                         print('COND','TRUE')\n",
    "                    else:\n",
    "                        cond_flag=False\n",
    "                    \n",
    "                    if ext_head_found or ext_single_page_head_found or ext_count>0:\n",
    "                        ext_flag=True\n",
    "#                         print('EXT','TRUE',pagenum)\n",
    "                    else:\n",
    "#                         print('EXT','FALSE',pagenum)\n",
    "                        ext_flag=False\n",
    "#                         print('COND','FALSE')\n",
    "#                     page_def_list.append({'name':term,'text':definitions[term][0]}\n",
    "#                     def_in_page=[{'name':k,'text':v[0]} for k,v in definitions.items() if v[1]==pagenum]  \n",
    "#                     print(def_in_page,'!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "                    for term,defs in definitions.items():\n",
    "                        if defs[1]==pagenum:  ###defs[1] is the pagenumber\n",
    "                            definition_text=definition_text+'          '+term+' '+defs[0]\n",
    "                            def_in_page.append({'name':term,'text':defs[0]})        \n",
    "#                     print(definition_text)\n",
    "                    if definition_text:\n",
    "                        def_flag=True\n",
    "\n",
    "                    if def_flag:\n",
    "                        def_search_flag=True\n",
    "#                         print('DEF','TRUE')\n",
    "                    else:\n",
    "                        def_search_flag=False\n",
    "#                         print('DEF','FALSE')\n",
    "                    \n",
    "                    if pg_no>2:\n",
    "                        endorsements=False\n",
    "                    else:\n",
    "                        endorsements=True\n",
    "#                     print(endorsements,'ENDORSEMENTS!!!')        \n",
    "                    if text_para in local_indexed.keys():\n",
    "                        text_para=text_para+' '\n",
    "                    local_indexed[text_para]=(file,pagenum,bold_lis,text_plain_para,excl_flag,excl_count,excl_pos_lis,subdir,sub_page_def_list,country,language,definition_text,def_search_flag,endorsements,excl_text,condition_text,cond_flag,cond_count,cond_pos_lis,def_in_page,ext_text,ext_flag,ext_count,ext_pos_lis)\n",
    "#                     print(sub_page_def_list,'DEF LIST!!!!!1')\n",
    "                    sub_page_def_list=[]\n",
    "                    text_para,text_plain_para='','' \n",
    "                    text_plain_lis,text_lis,bold_lis=[],[],[]\n",
    "                    definition_text=''\n",
    "                    single_page_head_found=False\n",
    "                    cond_single_page_head_found=False\n",
    "                    ext_single_page_head_found=False\n",
    "                    condition_text=''\n",
    "                    ext_text=''\n",
    "                    excl_text=''\n",
    "                    def_in_page=[]\n",
    "                    def_flag=False\n",
    "    return(local_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_pdf_path(path):\n",
    "    file_list=os.listdir(path)\n",
    "    for file in file_list:\n",
    "        raw_filename=file[:file.rfind(\".\")]\n",
    "        pdf_filename=raw_filename+'.pdf'\n",
    "#         print(raw_filename,pdf_filename,'FILE!!')\n",
    "        if pdf_filename in file_list:\n",
    "            print('continued!!!!!!!!!!!!!')\n",
    "            continue\n",
    "        if file.endswith('doc') or file.endswith('docx'):\n",
    "            print('processing!!!')\n",
    "            wordToPdf(os.path.join(path,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootDir='V://COG//AU- Property//'\n",
    "# for dirname,subdirlist,filelist in os.walk(rootDir):\n",
    "#     print(dirname)\n",
    "#     for subdir in subdirlist:\n",
    "#         path=os.path.join(dirname,subdir)\n",
    "# #         doc_pdf_path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Carrier Wording SUBDIR!!!!!!!!!!!!!\n",
      "Broker Wording SUBDIR!!!!!!!!!!!!!\n",
      "Chubb Standard Wording SUBDIR!!!!!!!!!!!!!\n",
      "OUTSIDE LOCATION CLAUSE.pdf\n",
      "COUNT 1\n",
      "BIOLOGICAL OR CHEMICAL MATERIALS EXCLUSION.pdf\n",
      "COUNT 2\n",
      "DEFINITIONS.pdf\n",
      "COUNT 3\n",
      "FOREIGN ENTITY LOSS CLAUSE.pdf\n",
      "COUNT 4\n",
      "COLLAPSE OF AERIAL CLAUSE.pdf\n",
      "COUNT 5\n",
      "HEATING AND POWER CLAUSE.pdf\n",
      "COUNT 6\n",
      "DIFFERENCE IN CONDITIONS DIFFERENCE IN LIMITS.pdf\n",
      "COUNT 7\n",
      "BREACH OF WARRANTIES CLAUSE.pdf\n",
      "COUNT 8\n",
      "SMOKE DAMAGE.pdf\n",
      "COUNT 9\n",
      "DIVISIBLE CONTROL CLAUSE.pdf\n",
      "COUNT 10\n",
      "ELECTRONIC DATE RECOGNITION EXCLUSION (EDRC) (A).pdf\n",
      "COUNT 11\n",
      "AWNINGS, BLINDS, SIGNS AND OUTDOOR FIXTURES OR FITTINGS OF ANY DESCRIPTION.pdf\n",
      "COUNT 12\n",
      "AUTOMATIC COVER FOR NEW LOCATIONS.pdf\n",
      "COUNT 13\n",
      "CLAIMS CO-OPERATION CLAUSE.pdf\n",
      "COUNT 14\n",
      "INTERLOCKING CLAUSE (CHARTIS_SPECIMEN).pdf\n",
      "COUNT 15\n",
      "INLAND TRANSIT (ALL RISKS) CLAUSE.pdf\n",
      "COUNT 16\n",
      "APPROVED ADJUSTERS - CUNNINGHAM AND INSIGHT.pdf\n",
      "COUNT 17\n",
      "Excluded Clauses.pdf\n",
      "COUNT 18\n",
      "ARMED ROBBERY AND OR HOLD UP CLAUSE.pdf\n",
      "COUNT 19\n",
      "DEBRIS REMOVAL.pdf\n",
      "COUNT 20\n",
      "AUTOMATIC REINSTATEMENT OF LOSS CLAUSE (AKA AMOUNT OF POLICY NOT REDUCED BY LOSS) (TW).pdf\n",
      "COUNT 21\n",
      "CONTRACT PRICE CLAUSE.pdf\n",
      "COUNT 22\n",
      "ACE EXTENDED PERIOD AGREEMENT.pdf\n",
      "COUNT 23\n",
      "IMPACT DAMAGE ENDORSEMENT.pdf\n",
      "COUNT 24\n",
      "FOLLOW THE LEAD CLAUSE ÔÇô ACCEPTABLE TO CHUBB.pdf\n",
      "COUNT 25\n",
      "LEAKAGE OF LIQUIDS CLAUSE.pdf\n",
      "COUNT 26\n",
      "COST OF RE ERECTION CLAUSE.pdf\n",
      "COUNT 27\n",
      "CLAIMS CONTROL CLAUSE (Terrorism LMA 5073).pdf\n",
      "COUNT 28\n",
      "MEMORANDUM - MATERIAL DAMAGE PROVISO ENDORSEMENT.pdf\n",
      "COUNT 29\n",
      "SUBSIDIARY COMPANIES CLAUSE.pdf\n",
      "COUNT 30\n",
      "Electronic Data Endorsement B û NMA 2915.pdf\n",
      "COUNT 31\n",
      "DEDUCTIBLE.pdf\n",
      "COUNT 32\n",
      "REPLACEMENT VALUE CLAUSE (NOT APPLICABLE TO STOCK).pdf\n",
      "COUNT 33\n",
      "DESCRIPTION OF PROPERTY INSURED.pdf\n",
      "COUNT 34\n",
      "AVERAGE RELIEF CLAUSE (NOT APPLICABLE TO STOCK) - 90 per cent.pdf\n",
      "COUNT 35\n",
      "REINSTATEMENT VALUE CLAUSE.pdf\n",
      "COUNT 36\n",
      "ADDITIONAL INCREASE IN COST OF WORKING.pdf\n",
      "COUNT 37\n",
      "SPONTANEOUS COMBUSTION ENDORSEMENT.pdf\n",
      "COUNT 38\n",
      "CLAIMS CO-OPERATION CLAUSE (Others.pdf\n",
      "COUNT 39\n",
      "CLAIMS CO-OPERATION CLAUSE (for OAC).pdf\n",
      "COUNT 40\n",
      "CAR ENDT UNDER IAR POLICY.pdf\n",
      "COUNT 41\n",
      "WAIVER OF SUBROGATION RIGHTS CLAUSE.pdf\n",
      "COUNT 42\n",
      "HIRING ENDORSEMENT.pdf\n",
      "COUNT 43\n",
      "CLAIMS CO-OPERATION (INDIAN OIL).pdf\n",
      "COUNT 44\n",
      "Contracts (Rights Of Third Parties) Act 2001.pdf\n",
      "COUNT 45\n",
      "UNDAMAGED FOUNDATIONS.pdf\n",
      "COUNT 46\n",
      "CLAIMS CO-OPERATION CLAUSE (BANYAN).pdf\n",
      "COUNT 47\n",
      "Sanction Related Exclusion.pdf\n",
      "COUNT 48\n",
      "Excluded Property.pdf\n",
      "COUNT 49\n",
      "TENANTS AND NEIGHBOURS.pdf\n",
      "COUNT 50\n",
      "NEWLY ACQUIRED PROPERTY.pdf\n",
      "COUNT 51\n",
      "COMBINED DEDUCTIBLE CLAUSE.pdf\n",
      "COUNT 52\n",
      "12 MONTHS BREAK AND REVIEW CLAUSE.pdf\n",
      "COUNT 53\n",
      "PRIVILEGES GRANTED.pdf\n",
      "COUNT 54\n",
      "TEMPORARY REMOVAL CLAUSE.pdf\n",
      "COUNT 55\n",
      "PAYMENT ON ACCOUNT CLAUSE  (FOR RENEWAL BUSINESS).pdf\n",
      "COUNT 56\n",
      "COST OF RECOMPILING RECORDS AND PREPARING CLAIMS CLAUSE.pdf\n",
      "COUNT 57\n",
      "FIRE BRIGADE CHARGES AND EXTINGUISHMENT EXPENSES CLAUSE.pdf\n",
      "COUNT 58\n",
      "SUE AND LABOUR CLAUSE.pdf\n",
      "COUNT 59\n",
      "ESCALATION CLAUSE.pdf\n",
      "COUNT 60\n",
      "LEASING ENDORSEMENT.pdf\n",
      "COUNT 61\n",
      "LOSS NOTIFICATION CLAUSE.pdf\n",
      "COUNT 62\n",
      "SERVICE CLAUSE.pdf\n",
      "COUNT 63\n",
      "FULL THEFT (NO SUBLIMIT-FROM SINGEX POLICY).pdf\n",
      "COUNT 64\n",
      "WORKMEN'S CLAUSE.pdf\n",
      "COUNT 65\n",
      "AVERAGE RELIEF CLAUSE - 115 per cent.pdf\n",
      "COUNT 66\n",
      "AUDITORS' FEES CLAUSE.pdf\n",
      "COUNT 67\n",
      "CUT THROUGH CLAUSE (MUNICH RE).pdf\n",
      "COUNT 68\n",
      "MORTGAGEE CLAUSE.pdf\n",
      "COUNT 69\n",
      "TEMPERATURE CLAUSE.pdf\n",
      "COUNT 70\n",
      "THEFT ENDORSEMENT (FIRST LOSS LIMIT).pdf\n",
      "COUNT 71\n",
      "CLAIMS CO-OPERATION CLAUSE (Petronet).pdf\n",
      "COUNT 72\n",
      "WAR AND CIVIL EXCLUSION (NMA464).pdf\n",
      "COUNT 73\n",
      "30 DAYS CANCELLATION CLAUSE.pdf\n",
      "COUNT 74\n",
      "TERRORISM EXCLUSION ENDORSEMENT (NMA 2920).pdf\n",
      "COUNT 75\n",
      "Time Limit.pdf\n",
      "COUNT 76\n",
      "EXPEDITING EXPENSES.pdf\n",
      "COUNT 77\n",
      "ULTIMATE NET LOSS (EXCESS REINSURANCE) CLAUSE (NMA457).pdf\n",
      "COUNT 78\n",
      "SUBSIDENCE AND LANDSLIP ENDORSEMENT.pdf\n",
      "COUNT 79\n",
      "SUBSIDENCE OR LANDSLIP.pdf\n",
      "COUNT 80\n",
      "Alteration.pdf\n",
      "COUNT 81\n",
      "Biological or Chemical Materials Exclusions û NMA 2962.pdf\n",
      "COUNT 82\n",
      "NON INVALIDATION CLAUSE.pdf\n",
      "COUNT 83\n",
      "DEFINITION OF LOSS OCCURRENCE.pdf\n",
      "COUNT 84\n",
      "TENANT'S CLAUSE.pdf\n",
      "COUNT 85\n",
      "ELECTRICAL INSTALLATION CLAUSE 4B.pdf\n",
      "COUNT 86\n",
      "INFECTIOUS DISEASE, MURDER AND CLOSURE.pdf\n",
      "COUNT 87\n",
      "LANDLORD CLAUSE.pdf\n",
      "COUNT 88\n",
      "CUSTOMERS' GOODS.pdf\n",
      "COUNT 89\n",
      "DIFFERNCE IN CONDITIONS (FIRE).pdf\n",
      "COUNT 90\n",
      "FOLLOW THE LEAD CLAUSE (AMENDED).pdf\n",
      "COUNT 91\n",
      "Property Damage Rate of Premium.pdf\n",
      "COUNT 92\n",
      "PAYMENT ON ACCOUNT CLAUSE  (FOR NEW BUSINESS).pdf\n",
      "COUNT 93\n",
      "Specific Compensation Schemes.pdf\n",
      "COUNT 94\n",
      "ADDITIONAL PERILS.pdf\n",
      "COUNT 95\n",
      "COLLECTIVE POLICY OF INSURANCE.pdf\n",
      "COUNT 96\n",
      "MEMO 1.pdf\n",
      "COUNT 97\n",
      "COST OF AND CLEARING AND ERECTION OF HOARDINGS CLAUSE.pdf\n",
      "COUNT 98\n",
      "War And Terrorism Exclusion Endorsement - NMA2918.pdf\n",
      "COUNT 99\n",
      "CLAIMS CONTROL CLAUSE.pdf\n",
      "COUNT 100\n",
      "INTERNAL REMOVAL CLAUSE.pdf\n",
      "COUNT 101\n",
      "FOOD OR DRINK POISONING; MURDER, SUICIDE POLICY EXTENSION.pdf\n",
      "COUNT 102\n",
      "CLAIMS CONTROL CLAUSE (CBK).pdf\n",
      "COUNT 103\n",
      "DIFFERENCE IN CONDITIONS.pdf\n",
      "COUNT 104\n",
      "FUNCTIONAL REINSTATEMENT VALUE.pdf\n",
      "COUNT 105\n",
      "WARRANTY 6C.pdf\n",
      "COUNT 106\n",
      "BRAND AND LABEL CLAUSE.pdf\n",
      "COUNT 107\n",
      "SELLING PRICE CLAUSE.pdf\n",
      "COUNT 108\n",
      "DENIAL OF ACCESS CLAUSE (CHUBB).pdf\n",
      "COUNT 109\n",
      "PROFESSIONAL FEES CLAUSE.pdf\n",
      "COUNT 110\n",
      "FOLLOW THE LEAD CLAUSE ÔÇô V1.pdf\n",
      "COUNT 111\n",
      "Political Risks Exclusion.pdf\n",
      "COUNT 112\n",
      "ELECTRONIC DATA ENDORSEMENT B (NMA 2915).pdf\n",
      "COUNT 113\n",
      "WARRANTY 19 (PETROL USAGE).pdf\n",
      "COUNT 114\n",
      "TRANSMISSION AND DISTRIBUTION LINES EXCLUSION (500 METRES).pdf\n",
      "COUNT 115\n",
      "ALTERATIONS AND REPAIRS CLAUSE.pdf\n",
      "COUNT 116\n",
      "BASIS OF CLAIMS SETTLEMENT.pdf\n",
      "COUNT 117\n",
      "INFECTIOUS OR CONTAGIOUS DISEASES, FOOD OR DRINK POISONING.pdf\n",
      "COUNT 118\n",
      "PROPERTY STORED ELSEWHERE.pdf\n",
      "COUNT 119\n",
      "Industrial All Risks - Wording.pdf\n",
      "COUNT 120\n",
      "FIRE BRIGADE CHARGES.pdf\n",
      "COUNT 121\n",
      "LAND COST CLAUSE.pdf\n",
      "COUNT 122\n",
      "EXPRESS CARRIAGE AND OVERTIME WORKING.pdf\n",
      "COUNT 123\n",
      "STANDARD DEDUCTIBLE CLAUSE.pdf\n",
      "COUNT 124\n",
      "SALVAGE AND RECOVERIES.pdf\n",
      "COUNT 125\n",
      "SUBTERRANEAN FIRE CLAUSE.pdf\n",
      "COUNT 126\n",
      "OUTBUILDING CLAUSE.pdf\n",
      "COUNT 127\n",
      "TIME ADJUSTMENT (SEVENTY-TWO HOUR).pdf\n",
      "COUNT 128\n",
      "FRAUDULENT OR DISHONEST ACTS.pdf\n",
      "COUNT 129\n",
      "WARRANTY.pdf\n",
      "COUNT 130\n",
      "MISDESCRIPTION CLAUSE.pdf\n",
      "COUNT 131\n",
      "FUEL GAS EXPLOSION ENDORSEMENT.pdf\n",
      "COUNT 132\n",
      "MORTGAGEE CHARGEE CLAUSE.pdf\n",
      "COUNT 133\n",
      "SUBROGATION.pdf\n",
      "COUNT 134\n",
      "CLAIMS CO-OPERATION CLAUSE (by PaulMcNamee).pdf\n",
      "COUNT 135\n",
      "CAPITAL ADDITIONS CLAUSE.pdf\n",
      "COUNT 136\n",
      "ARCHITECTS', SURVEYORS' AND CONSULTANT ENGINEERS' FEES CLAUSE.pdf\n",
      "COUNT 137\n",
      "SPECIFICATION FOR INSURANCE OF GROSS REVENUE.pdf\n",
      "COUNT 138\n",
      "CLAIMS CONTROL CLAUSE NMA 2738 (ACE).pdf\n",
      "COUNT 139\n",
      "LOSS PAYEE CLAUSE.pdf\n",
      "COUNT 140\n",
      "AUTOMATIC INCREASE.pdf\n",
      "COUNT 141\n",
      "CLAIMS CO-OPERATION CLAUSE (ACWA).pdf\n",
      "COUNT 142\n",
      "NO CONTROL CLAUSE.pdf\n",
      "COUNT 143\n",
      "AUDITORS' CHARGES CLAUSE.pdf\n",
      "COUNT 144\n",
      "Microorganism Exclusion (Map) (Absolute).pdf\n",
      "COUNT 145\n",
      "INFLATION GUARD ENDORSEMENT.pdf\n",
      "COUNT 146\n",
      "SUPPLIERS' CUSTOMERS' PREMISES CLAUSE.pdf\n",
      "COUNT 147\n",
      "HAZARDOUS GOODS WARRANTY 6A.pdf\n",
      "COUNT 148\n",
      "APPRAISEMENT CLAUSE.pdf\n",
      "COUNT 149\n",
      "SECONDARY LOCATIONS.pdf\n",
      "COUNT 150\n",
      "CLAIMS CO-OPERATION CLAUSE (SIA).pdf\n",
      "COUNT 151\n",
      "AVERAGE RELIEF CLAUSE  (NOT APPLICABLE TO STOCK) - 80 per cent.pdf\n",
      "COUNT 152\n",
      "SELF-IGNITION CLAUSE  FUSION DAMAGE.pdf\n",
      "COUNT 153\n",
      "ELECTRONIC DATA ENDORSEMENT A (NMA 2914).pdf\n",
      "COUNT 154\n",
      "PREMIUM AND ADJUSTMENT CLAUSE.pdf\n",
      "COUNT 155\n",
      "AVERAGE RELIEF CLAUSE (NOT APPLICABLE TO STOCK) - 85 per cent.pdf\n",
      "COUNT 156\n",
      "FOLLOW THE LEAD CLAUSE ÔÇô TUAS POWER.pdf\n",
      "COUNT 157\n",
      "DIFFERENCE IN CONDITIONS (CON LOSS).pdf\n",
      "COUNT 158\n",
      "CLAIMS CONTROL CLAUSE (Petron).pdf\n",
      "COUNT 159\n",
      "FAILURE OF PUBLIC UTILITIES CLAUSE.pdf\n",
      "COUNT 160\n",
      "ERRORS AND OMISSIONS CLAUSE.pdf\n",
      "COUNT 161\n",
      "CLAIMS CO-OPERATION CLAUSE NMA2737.pdf\n",
      "COUNT 162\n",
      "TERRORISM EXCLUSION ENDORSEMENT ÔÇô PROPERTY.pdf\n",
      "COUNT 163\n",
      "COST OF RE-WRITING RECORDS.pdf\n",
      "COUNT 164\n",
      "Transmission and Distribution Lines Exclusion.pdf\n",
      "COUNT 165\n",
      "PREMISES CLAUSE.pdf\n",
      "COUNT 166\n",
      "TREES, PLANTS AND SHRUBS.pdf\n",
      "COUNT 167\n",
      "AUTOMATIC REINSTATEMENT OF LOSS CLAUS1.pdf\n",
      "COUNT 168\n",
      "WAIVER OF SUBROGATION CLAUSE.pdf\n",
      "COUNT 169\n",
      "SPRINKLER LEAKAGE ENDORSEMENT.pdf\n",
      "COUNT 170\n",
      "CLAIMS CO-OPERATION CLAUSE (General Business Power Corp).pdf\n",
      "COUNT 171\n",
      "Fire Policy Wording.pdf\n",
      "COUNT 172\n",
      "ELECTRONIC DATE RECOGNITION EXCLUSION (EDRE).pdf\n",
      "COUNT 173\n",
      "BURGLARY ENDORSEMENT.pdf\n",
      "COUNT 174\n",
      "WARRANTY 2.pdf\n",
      "COUNT 175\n",
      "COMPANIES COLLECTIVE SIGNING FORM.pdf\n",
      "COUNT 176\n",
      "CLAIMS CO-OPERATION CLAUSE (CHUBB).pdf\n",
      "COUNT 177\n",
      "BUSH FIRE.pdf\n",
      "COUNT 178\n",
      "TRANSMISSION AND DISTRIBUTION LINES EXCLUSION (300 METRES).pdf\n",
      "COUNT 179\n",
      "LEASED PROPERTY CLAUSE.pdf\n",
      "COUNT 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronic Equipment and or Device Endorsement.pdf\n",
      "COUNT 181\n",
      "COST OF TEMPORARY PROTECTION CLAUSE.pdf\n",
      "COUNT 182\n",
      "CLAIMS CO-OPERATION CLAUSE (Bowring Marsh).pdf\n",
      "COUNT 183\n",
      "ALTERATIONS AND ADDITIONS CLAUSE.pdf\n",
      "COUNT 184\n",
      "BREACH OF CONDITIONS CLAUSE.pdf\n",
      "COUNT 185\n",
      "AGREED VALUE CLAUSE.pdf\n",
      "COUNT 186\n",
      "ELECTRICAL INSTALLATION CLAUSE 4A.pdf\n",
      "COUNT 187\n",
      "CO INSURANCE CLAUSE.pdf\n",
      "COUNT 188\n",
      "REMOVAL OF DEBRIS CLAUSE.pdf\n",
      "COUNT 189\n",
      "FULL THEFT (FIRST LOSS LIMIT).pdf\n",
      "COUNT 190\n",
      "Con Loss Wording.pdf\n",
      "COUNT 191\n",
      "LOSS OF ATTRACTION EXTENSION.pdf\n",
      "COUNT 192\n",
      "WARRANTY 1.pdf\n",
      "COUNT 193\n",
      "NON CANCELLATION CLAUSE.pdf\n",
      "COUNT 194\n",
      "BURGLARY ENDORSEMENT (FIRST LOSS LIMIT).pdf\n",
      "COUNT 195\n",
      "FIRE EXTINGUISHING COSTS.pdf\n",
      "COUNT 196\n",
      "EMPLOYEESÔÇÖ PERSONAL EFFECTS.pdf\n",
      "COUNT 197\n",
      "APPROVED ADJUSTERS CLAUSE.pdf\n",
      "COUNT 198\n",
      "AUTOMATIC INCLUSION OF NEW LOCATIONS.pdf\n",
      "COUNT 199\n",
      "VANDALISM AND MALICIOUS MISCHIEF ENDORSEMENT.pdf\n",
      "COUNT 200\n",
      "CONTROL OF PROPERTY.pdf\n",
      "COUNT 201\n",
      "SPECIAL CONDITIONS FOR DECLARATION POLICIES.pdf\n",
      "COUNT 202\n",
      "CO-INSURANCE CLAUSE - LEAD CLAUSE.pdf\n",
      "COUNT 203\n",
      "ELECTRONIC DATA EXCLUSION.pdf\n",
      "COUNT 204\n",
      "[A] Premium Payment Warranty [Usual Standard] û For Global Policy.pdf\n",
      "COUNT 205\n",
      "AUTOMOBILES CLAUSES.pdf\n",
      "COUNT 206\n",
      "CIVIL AUTHORITY CLAUSE.pdf\n",
      "COUNT 207\n",
      "PUBLIC AUTHORITIES CLAUSE.pdf\n",
      "COUNT 208\n",
      "DISPLAY AND EXHIBITION INSURANCE CLAUSE.pdf\n",
      "COUNT 209\n",
      "TENANTS' IMPROVEMENTS CLAUSE.pdf\n",
      "COUNT 210\n",
      "Claims.pdf\n",
      "COUNT 211\n",
      "BREACH OF WARRANTIES CONDITIONS CLAUSE.pdf\n",
      "COUNT 212\n",
      "[B] Premium Payment Warranty [Usual Standard].pdf\n",
      "COUNT 213\n",
      "INHIBITION COSTS.pdf\n",
      "COUNT 214\n",
      "WAR AND TERRORISM EXCLUSION ENDORSEMENT (NMA2918).pdf\n",
      "COUNT 215\n",
      "[C] Premium Payment Warranty [Instalment].pdf\n",
      "COUNT 216\n",
      "Seepage and or Pollution and or Contamination Exclusion.pdf\n",
      "COUNT 217\n",
      "DENIAL OF ACCESS CLAUSE.pdf\n",
      "COUNT 218\n",
      "HAZARDOUS GOODS CLAUSE.pdf\n",
      "COUNT 219\n",
      "OTHER CONTENTS CLAUSE.pdf\n",
      "COUNT 220\n",
      "COMPUTER SYSTEMS RECORDS.pdf\n",
      "COUNT 221\n",
      "DESIGNATION OF PROPERTY CLAUSE.pdf\n",
      "COUNT 222\n",
      "CLAIMS CO-OPERATION CLAUSE (Sumitomo).pdf\n",
      "COUNT 223\n",
      "CLOTHINGS AND OR PERSONAL EFFECTS.pdf\n",
      "COUNT 224\n",
      "RIOT AND STRIKE ENDORSEMENT  (FOR IAR POLICY ONLY).pdf\n",
      "COUNT 225\n",
      "EXTRA COST OF REINSTATEMENT.pdf\n",
      "COUNT 226\n",
      "WARRANTY 9(A).pdf\n",
      "COUNT 227\n",
      "Premium Payment Warranty.pdf\n",
      "COUNT 228\n",
      "RENT CLAUSE.pdf\n",
      "COUNT 229\n",
      "VEHICLE LOAD CLAUSE.pdf\n",
      "COUNT 230\n",
      "CLAIMS CONTROL CLAUSE (National Thermal Power).pdf\n",
      "COUNT 231\n",
      "Industry Standard Wording SUBDIR!!!!!!!!!!!!!\n",
      "Excluded Clauses.pdf\n",
      "COUNT 232\n",
      "Electronic Data Endorsement B û NMA 2915.pdf\n",
      "COUNT 233\n",
      "ELECTRONIC EQUIPMENT AND OR DEVICE ENDORSEMENT.pdf\n",
      "COUNT 234\n",
      "Contracts (Rights Of Third Parties) Act 2001.pdf\n",
      "COUNT 235\n",
      "Sanction Related Exclusion.pdf\n",
      "COUNT 236\n",
      "Excluded Property.pdf\n",
      "COUNT 237\n",
      "Time Limit.pdf\n",
      "COUNT 238\n",
      "Alteration.pdf\n",
      "COUNT 239\n",
      "Biological or Chemical Materials Exclusions û NMA 2962.pdf\n",
      "COUNT 240\n",
      "Property Damage Rate of Premium.pdf\n",
      "COUNT 241\n",
      "Specific Compensation Schemes.pdf\n",
      "COUNT 242\n",
      "Chubb Industry ISR Mark IV Wording.pdf\n",
      "COUNT 243\n",
      "War And Terrorism Exclusion Endorsement - NMA2918.pdf\n",
      "COUNT 244\n",
      "Political Risks Exclusion.pdf\n",
      "COUNT 245\n",
      "TRANSMISSION AND DISTRIBUTION LINES EXCLUSION.pdf\n",
      "COUNT 246\n",
      "MICROORGANISM EXCLUSION (MAP) (Absolute).pdf\n",
      "COUNT 247\n",
      "[A] Premium Payment Warranty [Usual Standard] û For Global Policy.pdf\n",
      "COUNT 248\n",
      "Claims.pdf\n",
      "COUNT 249\n",
      "[B] Premium Payment Warranty [Usual Standard].pdf\n",
      "COUNT 250\n",
      "[C] Premium Payment Warranty [Instalment].pdf\n",
      "COUNT 251\n",
      "Seepage and or Pollution and or Contamination Exclusion.pdf\n",
      "COUNT 252\n",
      "Premium Payment Warranty.pdf\n",
      "COUNT 253\n",
      "Bespoke Wording SUBDIR!!!!!!!!!!!!!\n",
      "Bespoke Wording - Sakari Resources Limited - 70552448 PoI - 01-01-2019 to 31-12-2019.pdf\n",
      "COUNT 254\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "file_count=0\n",
    "rootDir='Documents/SG-Property/'\n",
    "country='singapore'\n",
    "local_indexed={}\n",
    "language='english'\n",
    "if 'spanish' in rootDir:\n",
    "    language='spanish'\n",
    "for dirname,subdirlist,filelist in os.walk(rootDir):\n",
    "    for subdir in subdirlist:\n",
    "        print(subdir, 'SUBDIR!!!!!!!!!!!!!')\n",
    "        path=os.path.join(dirname,subdir)    \n",
    "        local_indexed_subdir=create_local_index(path,subdir,language,country)\n",
    "        local_indexed.update(local_indexed_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(local_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "\n",
    "cosmo_endpoint=\"https://nf-poc-cdb-sql.documents.azure.com\"\n",
    "cosmo_key=\"iEcEfrxYe0Fm9QtoxDrOpLvGsfzjowwybULlWT9Uz4XxV4RmOIAnRuLdgRFUu1LPU5Vwk3UGivRrPrxnk7083w==\"\n",
    "client = CosmosClient(cosmo_endpoint, cosmo_key)\n",
    "database=client.get_database_client('policy-analysis')\n",
    "container=database.get_container_client('property-wordings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Conflict) Entity with the specified id already exists in the system., \n",
      "RequestStartTime: 2020-12-16T16:12:09.3759829Z, RequestEndTime: 2020-12-16T16:12:09.3759829Z,  Number of regions attempted:1\n",
      "ResponseTime: 2020-12-16T16:12:09.3759829Z, StoreResult: StorePhysicalAddress: rntbd://cdb-ms-prod-eastus1-fd58.documents.azure.com:14073/apps/f731575d-fb29-4640-9ffc-a6de234ddc91/services/78ee78c6-b247-456d-ab37-8e45873f3782/partitions/0e690849-4cb2-4a3c-b969-080feeb81a53/replicas/132525678004960632p/, LSN: 575, GlobalCommittedLsn: 575, PartitionKeyRangeId: 0, IsValid: True, StatusCode: 409, SubStatusCode: 0, RequestCharge: 1.67, ItemLSN: -1, SessionToken: -1#575, UsingLocalLSN: False, TransportException: null, ResourceType: Document, OperationType: Create\n",
      ", Microsoft.Azure.Documents.Common/2.11.0\n",
      "(Conflict) Entity with the specified id already exists in the system., \n",
      "RequestStartTime: 2020-12-16T16:12:10.6259823Z, RequestEndTime: 2020-12-16T16:12:10.6259823Z,  Number of regions attempted:1\n",
      "ResponseTime: 2020-12-16T16:12:10.6259823Z, StoreResult: StorePhysicalAddress: rntbd://cdb-ms-prod-eastus1-fd58.documents.azure.com:14073/apps/f731575d-fb29-4640-9ffc-a6de234ddc91/services/78ee78c6-b247-456d-ab37-8e45873f3782/partitions/0e690849-4cb2-4a3c-b969-080feeb81a53/replicas/132525678004960632p/, LSN: 604, GlobalCommittedLsn: 604, PartitionKeyRangeId: 0, IsValid: True, StatusCode: 409, SubStatusCode: 0, RequestCharge: 1.76, ItemLSN: -1, SessionToken: -1#604, UsingLocalLSN: False, TransportException: null, ResourceType: Document, OperationType: Create\n",
      ", Microsoft.Azure.Documents.Common/2.11.0\n"
     ]
    }
   ],
   "source": [
    "for key,value in local_indexed.items():\n",
    "    doc={}\n",
    "    doc['text']=key\n",
    "    doc['page']=int(value[1])\n",
    "    if value[4]==True or value[0].find('Exclusion')!=-1:\n",
    "        doc['IsExclusion']=True\n",
    "    else:\n",
    "        doc['IsExclusion']=False\n",
    "    doc['doc_name']=value[0].replace('.pdf','')\n",
    "    doc['id']=doc['doc_name']+' '+str(doc['page'])\n",
    "    doc['bold_phrases']=value[2]\n",
    "    doc['plain_text']=value[3]\n",
    "    doc['excl_count']=value[5]\n",
    "    doc['excl_pos']=value[6]\n",
    "    doc['folder']=value[7]\n",
    "    doc['definitions']=[{'name':key,'text':value} for key,value in re.findall('###(.*?)@@(.*?)%%%',doc['text'])]\n",
    "    doc['country']=value[9]\n",
    "    doc['language']=value[10]\n",
    "    doc['definition_text']=value[11]\n",
    "#     print(doc['definition_text'],'\\n\\n')\n",
    "    if doc['definition_text']:\n",
    "        doc['definition_flag']=True\n",
    "    else:\n",
    "        doc['definition_flag']=False\n",
    "    if value[14]==True or 'endorsement' in value[0].lower(): \n",
    "        doc['endorsements']=True\n",
    "    else:\n",
    "        doc['endorsements']=value[13]\n",
    "    doc['excl_text']=value[14]\n",
    "    doc['cond_text']=value[15]\n",
    "    doc['cond_flag']=value[16]\n",
    "    doc['cond_count']=value[17]\n",
    "    doc['cond_pos']=value[18]\n",
    "    doc['definitions_in_page']=value[19]\n",
    "    doc['ext_text']=value[20]\n",
    "    doc['ext_flag']=value[21]\n",
    "    doc['ext_count']=value[22]\n",
    "    doc['ext_pos']=value[23]\n",
    "    \n",
    "    try:       \n",
    "        container.create_item(body=doc)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added to cosmos\n"
     ]
    }
   ],
   "source": [
    "print('added to cosmos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
