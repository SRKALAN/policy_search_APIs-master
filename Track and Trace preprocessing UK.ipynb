{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal\n",
    "from contextlib import contextmanager\n",
    "\n",
    "class TimeoutException(Exception): pass\n",
    "\n",
    "@contextmanager\n",
    "def time_limit(seconds):\n",
    "    def signal_handler(signum, frame):\n",
    "        raise TimeoutException(\"Timed out!\")\n",
    "    signal.signal(signal.SIGALRM, signal_handler)\n",
    "    signal.alarm(seconds)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# !pip install fitz\n",
    "# import comtypes.client\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "def wordToPdf(file1):\n",
    "    wdFormatPDF = 17\n",
    "    input_file = os.path.abspath(file1)\n",
    "    output_file = os.path.splitext(input_file)[0]+\".pdf\"\n",
    "    output_file = os.path.abspath(output_file)\n",
    "    word = comtypes.client.CreateObject('Word.Application')\n",
    "    word.Visible = True\n",
    "    time.sleep(3)\n",
    "    \n",
    "    doc = word.Documents.Open(input_file)\n",
    "\n",
    "    doc.SaveAs(output_file, FileFormat=wdFormatPDF)\n",
    "\n",
    "    doc.Close()\n",
    "    word.Quit()\n",
    "\n",
    "    return output_file\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app/RB/.local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.2) or chardet (4.0.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import uuid\n",
    "from statistics import mode\n",
    "from nltk.corpus import stopwords\n",
    "from pdf2txt import convert_pdf\n",
    "# !pip install tika\n",
    "import tika\n",
    "from definitions_v4 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsRE_heading=re.compile('(?:\\s*\\([a-z]{1,3}\\)|[A-Z]{1}\\s+[a-zA-Z0-9_\\s]{5})')\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "y_cordinate_Re=re.compile('top:(\\d{1,5})px')\n",
    "height_re=re.compile('height:(\\d{1,5})px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_underline(positions,y_cord_text):\n",
    "    positions=[i for i in positions if y_cord_text<=i< y_cord_text+16]\n",
    "    if positions:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_no(soup):\n",
    "    total_items = int(soup.find('span', id='NewReleases_total').text)\n",
    "    items_per_page = int(soup.find('span', id='NewReleases_end').text)\n",
    "    return round(total_items/items_per_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "\n",
    "# print(len(list(extract_pages('test/Chubb16-250-1019 Chubb EBM Business Pack Product Disclosure Statement (PDS) and Policy Wording.pdf'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_underlines(soup):\n",
    "    positions=[]\n",
    "    for span in soup.find_all('span'):\n",
    "        y_cord_list=y_cordinate_Re.findall(str(span))\n",
    "        if y_cord_list:\n",
    "            y_cord=int(y_cord_list[0])\n",
    "        else:\n",
    "            continue\n",
    "        style=\"position:absolute; border: black 1px solid\" in str(span)\n",
    "        height_px_li=height_re.findall(str(span))\n",
    "        if height_px_li:\n",
    "            height_px=height_px_li[0]\n",
    "        else:\n",
    "            continue\n",
    "        height=int(height_px)<15\n",
    "        if all([style,height]):\n",
    "            positions.append(y_cord)\n",
    "    return list(set(positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_extract(text_list,language):\n",
    "    ext_flag=False\n",
    "    if language=='english':\n",
    "        ext_lis=['extension']\n",
    "    else:\n",
    "        ext_lis=['extensión','extensiones']\n",
    "   \n",
    "    ext_count=0\n",
    "    position_list=[]\n",
    "    position=0\n",
    "    for text in text_list:\n",
    "        # if any two of 'exclusion ,condition or extension is present in the text, that text is omitted from the logic'\n",
    "        bool_list=['condition' in text.lower(),'exclusion' in text.lower(),'extension' in text.lower()]\n",
    "        if sum(bool_list)>=2:\n",
    "            continue\n",
    "        for i in ext_lis:\n",
    "            for match in re.finditer(i, text.lower()):\n",
    "                position_list.append(position+match.start())               \n",
    "                ext_count+=1\n",
    "        position+=len(text)\n",
    "    if ext_count>=1:\n",
    "        ext_flag=True\n",
    "    return(ext_flag,ext_count,position_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excl_extract(text_list,language):\n",
    "    exclusion_flag=False\n",
    "    if language=='english':\n",
    "        excl_lis=['exclud','not cover','except','does not mean','not includ','exclusion']\n",
    "    else:\n",
    "        excl_lis=['excepto','excepción','no in cluido','exclusión','excluidos','excluirlo','excluyendo','exclusiones','exclusion','excluyen','excluyentes']\n",
    "   \n",
    "    exclusion_count=0\n",
    "    position_list=[]\n",
    "    position=0\n",
    "    for text in text_list:\n",
    "        # if any two of 'exclusion ,condition or extension is present in the text, that text is omitted from the logic'\n",
    "        bool_list=['condition' in text.lower(),'exclusion' in text.lower(),'extension' in text.lower()]\n",
    "        if sum(bool_list)>=2:\n",
    "            continue\n",
    "        for i in excl_lis:\n",
    "            for match in re.finditer(i, text.lower()):\n",
    "                position_list.append(position+match.start())               \n",
    "                exclusion_count+=1\n",
    "        position+=len(text)\n",
    "    if exclusion_count>=1:\n",
    "        exclusion_flag=True\n",
    "    return(exclusion_flag,exclusion_count,position_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_check(text,language):\n",
    "    if language=='english':\n",
    "        ext_bag=['extension']\n",
    "    else:\n",
    "        ext_bag=['extensión','extensiones']\n",
    "    for word in ext_bag:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_extract(text_list,language):\n",
    "    cond_flag=False\n",
    "    if language=='english':\n",
    "        cond_lis=['condition']\n",
    "    else:\n",
    "        cond_lis=['condición','condiciones','condicionado']\n",
    "   \n",
    "    cond_count=0\n",
    "    position_list=[]\n",
    "    position=0\n",
    "    for text in text_list:\n",
    "        # if any two of 'exclusion ,condition or extension is present in the text, that text is omitted from the logic'\n",
    "        bool_list=['condition' in text.lower(),'exclusion' in text.lower(),'extension' in text.lower()]\n",
    "        if sum(bool_list)>=2:\n",
    "            continue\n",
    "        for i in cond_lis:\n",
    "            for match in re.finditer(i, text.lower()):\n",
    "                position_list.append(position+match.start())               \n",
    "                cond_count+=1\n",
    "        position+=len(text)\n",
    "    if cond_count>=1:\n",
    "        cond_flag=True\n",
    "    return(cond_flag,cond_count,position_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_extraction(soup):\n",
    "    fontsizes=[]\n",
    "    for divs in soup.findAll('div'):\n",
    "        for j in divs.find_all('span'):\n",
    "            ext_size=re.findall(r'font-size:(.*)px\">',str(j))\n",
    "            if ext_size:\n",
    "                fontsizes.append(int(ext_size[0]))\n",
    "    return(fontsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_box(positions,y_cord_text):\n",
    "    positions=[i for i in positions if y_cord_text-7 <=i< y_cord_text]\n",
    "    if positions:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_underlines_n_boxes(soup):\n",
    "    underline_positions=[]\n",
    "    box_positions=[]\n",
    "    for span in soup.find_all('span'):\n",
    "        y_cord_list=y_cordinate_Re.findall(str(span))\n",
    "       \n",
    "        if y_cord_list:\n",
    "            y_cord=int(y_cord_list[0])\n",
    "        else:\n",
    "            continue\n",
    "        style=\"position:absolute; border: black 1px solid\" in str(span)\n",
    "        height_px_li=height_re.findall(str(span))\n",
    "        if height_px_li:\n",
    "            height_px=height_px_li[0]\n",
    "        else:\n",
    "            continue\n",
    "        height=int(height_px)<15\n",
    "        heigh_box=18<=int(height_px)<50\n",
    "       \n",
    "        if all([style,height]):\n",
    "            underline_positions.append(y_cord)\n",
    "        elif all([style,heigh_box]) :\n",
    "            box_positions.append(y_cord)\n",
    "#             print(height_px,'HEIGHT_BOX')\n",
    "#             print()\n",
    "#             print(y_cord,'YCHORDDDD')\n",
    "           \n",
    "    return list(set(underline_positions)),list(set(box_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_check(word,text,language):\n",
    "    if language=='spanish':\n",
    "        stop_words = list(set(stopwords.words('spanish')))\n",
    "    else:\n",
    "        stop_words = list(set(stopwords.words('english')))\n",
    "        transition=\"although  instead  whereas  despite  conversely  otherwise  however moreover  likewise  comparatively  correspondingly  similarly  furthermore  additionallyver  rather  nevertheless  nonetheless  regardless  notwithstanding consequently  therefore  thereupon  forthwith  accordingly  henceforth\"\n",
    "        transition_words=transition.split()\n",
    "        transition_words\n",
    "        stop_words.extend(transition_words)\n",
    "\n",
    "    if exclusion_check(text,language):\n",
    "        return True\n",
    "    if word.lower() in stop_words:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclusion_check(text,language):\n",
    "    if language=='spanish':\n",
    "        exclusion_bag=['excepto','excepción','no in cluido','exclusión','excluidos','excluirlo','excluyendo',' excluyen','exclusiones','exclusiones','exclusion','excluyentes']\n",
    "    else:\n",
    "        exclusion_bag=['exclusion','excluded','not covered','will not cover','will not pay']\n",
    "    for word in exclusion_bag:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criteria_check(text,language):\n",
    "    if language=='spanish':\n",
    "        exclusion_bag=['condición','condiciones','condicionado']\n",
    "    else:\n",
    "        exclusion_bag=['condition','conditions']\n",
    "    for word in exclusion_bag:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_check(text,language):\n",
    "    if language=='english':\n",
    "        ext_bag=['extension']\n",
    "    else:\n",
    "        ext_bag=['extensión','extensiones']\n",
    "    for word in ext_bag:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endorsement_check(text,language):\n",
    "    if language=='english':\n",
    "        ext_bag=['additional terms and conditions','endorsement 1']\n",
    "#     else:\n",
    "#         ext_bag=['extensión','extensiones']\n",
    "    for word in ext_bag:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ins_agg_check(text,language):\n",
    "    if language=='spanish':\n",
    "        exclusion_bag=['excepto','excepción','no in cluido','exclusión','excluidos','excluirlo','excluyendo',' excluyen','exclusiones','exclusiones','exclusion','excluyentes']\n",
    "    else:\n",
    "        exclusion_bag=['appendix','contact us','about chubb','introduction','general information','tax audit','financial strength rating','fair insurance code','duty of disclosure','privacy statement','important information','important notices','finance act','insurance act','authorization and regulation','french prudential supervision and resolution authority','compensation scheme','financial services','product disclosure','insurer complaints procedure','dispute resolution','complaints procedure','exclusion','excluded','not covered','will not cover','will not pay','additional terms and conditions','condition','conditions','definition','extension','data protection']\n",
    "    for word in exclusion_bag:\n",
    "        if word in text.lower():\n",
    "            return False\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=re.compile('.*\\d{1,3}.*(?:\\-|\\.|–)')\n",
    "def clean(text):\n",
    "    text=text.replace('\\n','').replace('\\t',' ')\n",
    "    text=start.sub('',text).strip()\n",
    "    \n",
    "\n",
    "    return(text)\n",
    "def clean_pharses(phrases):\n",
    "    phrases=[clean(i) for i in phrases if len(i)> 3]\n",
    "    phrases=list(set(phrases))\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_index(path,subdir,language,country):\n",
    "    pointsRE_heading=re.compile('(?:\\s*\\([a-z]{1,3}\\)|(?<![A-z])[A-Z]{1}\\s+[a-zA-Z0-9_\\s]{5})')\n",
    "    pageNumRE=re.compile('Page\\s*(\\d{1,3})',re.IGNORECASE)\n",
    "    neglect_def=['policy','insured','schedule']\n",
    "    local_indexed={}\n",
    "    previous_span=''\n",
    "    bold_phrases_indexed={}\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.pdf'):\n",
    "            print(file)\n",
    "            try:\n",
    "                pg_no=len(list(extract_pages(os.path.join(path,file))))\n",
    "            except:\n",
    "                pg_no=0\n",
    "            try:\n",
    "                html=convert_pdf(os.path.join(path,file),'html')\n",
    "            except:\n",
    "                continue\n",
    "            soup = BeautifulSoup(html, 'html5lib')\n",
    "            underline_positions,box_positions=get_underlines_n_boxes(soup)\n",
    "            \n",
    "            try:\n",
    "                fontsizes=font_extraction(soup)\n",
    "                file_font_size_mode=mode(fontsizes)\n",
    "            except:\n",
    "                file_font_size_mode=8\n",
    "                \n",
    "            text_para,text_plain_para='',''\n",
    "            text_lis,text_plain_lis,bold_lis,page_list,=[],[],[],[]\n",
    "            bold=False\n",
    "            sub_page_def_list=[]\n",
    "            try:\n",
    "                definitions=def_extraction2(os.path.join(path,file))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            definitions={key:value for key,value in definitions.items() if key.lower().strip() not in neglect_def}\n",
    "            def_terms=list(definitions.keys())\n",
    "            definition_text=''\n",
    "            header_match_object=(0,'',False)\n",
    "            cond_header_match_object=(0,'',False)\n",
    "            ext_header_match_object=(0,'',False)\n",
    "            endorsement_header_match_object=(0,'',False)\n",
    "            ins_agg_header_match_object=(0,'',False)\n",
    "            endorsement_y_cord=0\n",
    "            second_category=False\n",
    "            head_found=False\n",
    "            def_flag=False\n",
    "            span_text_pos=0\n",
    "            header_pos=[]\n",
    "            cond_head_found=False\n",
    "            ext_head_found=False\n",
    "            endorsement_head_found=False\n",
    "            ins_agg_head_found=False\n",
    "            single_page_head_found=False\n",
    "            condition_text=''\n",
    "            ext_text=''\n",
    "            excl_text=''\n",
    "            endorsement_text=''\n",
    "            ins_agg_text=''\n",
    "            previous_pg_num=[]\n",
    "            def_in_page=[]\n",
    "            cond_single_page_head_found=False\n",
    "            ext_single_page_head_found=False\n",
    "            endorsement_single_page_head_found=False\n",
    "            ins_agg_single_page_head_found=False\n",
    "            \n",
    "            font_size=file_font_size_mode\n",
    "\n",
    "            for divs in soup.findAll('div'):\n",
    "                div_text_list=[span.text for span in divs.find_all('span') ]\n",
    "                page_str=str(divs.find_all('a'))\n",
    "                page_num_results=pageNumRE.findall(page_str)\n",
    "                if page_num_results:\n",
    "                    pagenum=page_num_results[0]\n",
    "\n",
    "                    if pagenum!=previous_pg_num:\n",
    "                        sub_definitions_in_page=[]\n",
    "                    previous_pg_num=pagenum\n",
    "\n",
    "                    if text_lis:\n",
    "                        text_lis=text_lis[:-1]\n",
    "                        text_para=''.join(text_lis)\n",
    "                        text_plain_lis=text_plain_lis[:-1]\n",
    "                        text_plain_para=''.join(text_plain_lis)\n",
    "                        if(len(re.findall('\\.',text_para))>(len(text_para)/3) or (len(re.findall('\\d',text_para))>50 and 'gbp' not in text_para.lower() and 'content' in text_para.lower())): # and int(pagenum)<=2\n",
    "                            print('PASS')\n",
    "                            text_para,text_plain_para=' ',' '\n",
    "                            text_lis,text_plain_lis=[],[]\n",
    "                            single_page_head_found=False\n",
    "                            head_found=False\n",
    "                            span_text_pos=0\n",
    "                            header_pos=[]\n",
    "                            cond_head_found=False\n",
    "                            ext_head_found=False\n",
    "                            endorsement_head_found=False\n",
    "                            ins_agg_head_found=False\n",
    "                            continue\n",
    "                        \n",
    "                        else:\n",
    "                            bold_lis=clean_pharses(bold_lis)\n",
    "                            pagenum=int(pagenum)-1\n",
    "                            excl_flag,excl_count,excl_pos_lis=excl_extract(text_plain_lis,language)\n",
    "                            cond_flag,cond_count,cond_pos_lis=cond_extract(text_plain_lis,language)\n",
    "                            ext_flag,ext_count,ext_pos_lis=ext_extract(text_plain_lis,language)\n",
    "                            if int(pagenum)==1:\n",
    "                                if head_found or single_page_head_found or excl_count>0:\n",
    "                                    excl_flag=True\n",
    "                                else:\n",
    "                                    excl_flag=False\n",
    "                            else:\n",
    "                                if head_found or single_page_head_found:\n",
    "                                    excl_flag=True\n",
    "\n",
    "                            if cond_head_found or cond_single_page_head_found or cond_count>0:\n",
    "                                cond_flag=True\n",
    "                            else:\n",
    "                                cond_flag=False\n",
    "    \n",
    "                            if ext_head_found or ext_single_page_head_found or ext_count>0:\n",
    "                                ext_flag=True\n",
    "                            else:\n",
    "                                ext_flag=False\n",
    "    \n",
    "                            if endorsement_head_found or endorsement_single_page_head_found:\n",
    "                                endorsement_flag=True\n",
    "                                print(pagenum,endorsement_flag)\n",
    "                            else:\n",
    "                                endorsement_flag=False\n",
    "                                print(pagenum,endorsement_flag)\n",
    "                            \n",
    "                            if ins_agg_head_found or ins_agg_single_page_head_found:\n",
    "                                ins_agg_flag=True\n",
    "#                                 print(pagenum,True)\n",
    "                            else:\n",
    "                                ins_agg_flag=False\n",
    "#                                 print(pagenum,False)\n",
    "                                \n",
    "                            for term,defs in definitions.items():\n",
    "                                if defs[1]==pagenum:  ###defs[1] is the pagenumber\n",
    "                                    definition_text=definition_text+'          '+term+' '+defs[0]\n",
    "                                    def_in_page.append({'name':term,'text':defs[0]})\n",
    "\n",
    "                            if definition_text:\n",
    "                                def_flag=True\n",
    "                            \n",
    "                            if def_flag:\n",
    "                                def_search_flag=True\n",
    "                            else:\n",
    "                                def_search_flag=False   \n",
    "                            \n",
    "                            if pg_no>2:\n",
    "                                endorsements=False\n",
    "                            else:\n",
    "                                endorsements=True\n",
    "#                             print('PAGE',pagenum)\n",
    "#                             print(endorsements,'ENDORSEMENTS!!!')\n",
    "                            if text_para in local_indexed.keys():\n",
    "                                text_para=text_para+' '\n",
    "                            \n",
    "                            local_indexed[text_para]=(file,pagenum,bold_lis,text_plain_para,excl_flag,excl_count,excl_pos_lis,subdir,sub_page_def_list,country,language,definition_text,def_search_flag,endorsements,excl_text,condition_text,cond_flag,cond_count,cond_pos_lis,def_in_page,ext_text,ext_flag,ext_count,ext_pos_lis,span_text_pos,header_pos,endorsement_flag,endorsement_text,ins_agg_flag,ins_agg_text)\n",
    "#                             print(sub_page_def_list,'DEF LIST!!!!!1')\n",
    "                            sub_page_def_list=[]\n",
    "                            span_text_pos=0\n",
    "                            header_pos=[]\n",
    "                            page_list.append(pagenum)\n",
    "                            text_para,text_plain_para='',''\n",
    "                            text_lis,text_plain_lis,bold_lis=[],[],[]\n",
    "                            definition_text=''\n",
    "                            span_text_pos=0\n",
    "                            cond_single_page_head_found=False\n",
    "                            ext_single_page_head_found=False\n",
    "                            endorsement_single_page_head_found=False\n",
    "                            ins_agg_single_page_head_found=False\n",
    "                            condition_text=''\n",
    "                            ext_text=''\n",
    "                            excl_text=''\n",
    "                            ins_agg_text=''\n",
    "                            endorsement_text=''\n",
    "                            single_page_head_found=False\n",
    "                            def_in_page=[]\n",
    "                            def_flag=False\n",
    "                for span in divs.find_all('span'):\n",
    "\n",
    "                    bold=False\n",
    "                    upper=False\n",
    "                    bullet=False\n",
    "                    def_flag=False\n",
    "                    span_position=div_text_list.index(span.text)\n",
    "#                     span_text_pos+=len(span.text)\n",
    "# #                     print(span_text_pos,'SPAN POS')\n",
    "                    if \"Bold\" in str(span) or 'CIDFont+F3' in str(span):\n",
    "                        bold_lis.append(span.text)\n",
    "                        bold=True\n",
    "                    if span.text.isupper():\n",
    "                        upper=True\n",
    "                    font_family_match=re.findall(r\"font-family: b'(.*)';\",str(span))\n",
    "                    if font_family_match:\n",
    "                        font_family=font_family_match[0]\n",
    "                    else:\n",
    "                        font_family=''\n",
    "#                     print(font_family)\n",
    "                    font_size_match=re.findall(r'font-size:(.*)px\">',str(span))\n",
    "                    if font_size_match:\n",
    "                        font_size=int(font_size_match[0])\n",
    "                    if pointsRE_heading.findall(span.text):\n",
    "                        bullet=True\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "                    y_cord_list=y_cordinate_Re.findall(str(divs))\n",
    "                    if y_cord_list:\n",
    "                        y_cord=int(y_cord_list[0])\n",
    "#                     underlined_text=check_underline(underline_positions,y_cord)\n",
    "                    underlined_text=check_underline(underline_positions,y_cord)\n",
    "                    \n",
    "                    boxed_text=check_box(box_positions,y_cord)\n",
    "#                     if 'Endorsement 1' in span.text:\n",
    "#                         print(box_positions,y_cord,'BOX POS AND Y')\n",
    "                    if span.text.split('\\n')[0]!='' and span.text.split('\\n')[0]!=' ':\n",
    "                        head_check_text=span.text.split('\\n')[0]\n",
    "                    elif len(span.text.split('\\n'))>1:\n",
    "                        head_check_text=span.text.split('\\n')[1]\n",
    "                    else:\n",
    "                        head_check_text=''\n",
    "##############################3  \n",
    "                    if str(previous_span).endswith('<br/></span>'):\n",
    "                        span_position=0\n",
    "                    ##################INSERT FUNCTION####################z\n",
    "                    #EXCLUSION \n",
    "                    if  span_position==0 and (bold or font_size>= file_font_size_mode +2 ) and (font_size> file_font_size_mode or upper) and 5<len(head_check_text.strip())<80:                    \n",
    "                        header_pos.append(span_text_pos)\n",
    "#                         print('HEADER FOUND', span.text,span_text_pos)\n",
    "                        if exclusion_check(head_check_text,language) and not head_found: \n",
    "                            head_found=True\n",
    "                            header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "                            First_category=True\n",
    "                            second_category=False\n",
    "                            single_page_head_found=True\n",
    "#                             print('FOUND Heading for exclusion ...',span.text)\n",
    "          \n",
    "    \n",
    "                        elif ((font_size,font_family,bold,upper,bullet)==header_match_object  or font_size>header_match_object[0] ) and head_found and not exclusion_check(head_check_text,language):\n",
    "                            head_found=False\n",
    "                            single_page_head_found=True\n",
    "#                             print('FOUND Closure for exclusion ...',span.text)\n",
    "#                     if 'CLAIMS CONDITIONS' in span.text:\n",
    "#                         print ('^^^^^^^',(font_size,font_family,bold,upper,bullet),header_match_object, font_size>header_match_object[0] , head_found , not exclusion_check(head_check_text,language))\n",
    "#                         print(pointsRE_heading.findall(span.text))\n",
    "                    words_title=[word.istitle() for word in head_check_text.split() if stopword_check(word,head_check_text,language) and not word.isdigit() ]\n",
    "                    if span_position==0 and all(words_title) and head_check_text.strip() not in definitions and  (len(words_title) >1 or underlined_text )and 5<len(head_check_text.strip())<80 :\n",
    "#                         print('MMMMMMMMARARARA',span.text)\n",
    "                        header_pos.append(span_text_pos)\n",
    "#                         print('HEADER 2 FOUND', span.text,span_text_pos)\n",
    "                        if exclusion_check(head_check_text,language) and  not head_found:\n",
    "                            head_found=True\n",
    "                            second_category=True\n",
    "                            First_category=False\n",
    "                            single_page_head_found=True\n",
    "                            header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "#                             print(\"FOUND Exclusion heading type2 ....\",span.text)\n",
    "                        elif head_found and not exclusion_check(head_check_text,language) and second_category and ((font_size,font_family,bold,upper,bullet)==header_match_object or font_size > header_match_object[0] ) :\n",
    "                            head_found=False\n",
    "                            second_category=False\n",
    "                            single_page_head_found=True\n",
    "#                             print('FOUND Exclusion closure type 2',span.text)\n",
    "                    if head_found:\n",
    "                        excl_text=excl_text+' '+span.text     \n",
    "                     \n",
    "                    #CONDITIONS\n",
    "                    if  span_position==0 and (bold or font_size>= file_font_size_mode +2 ) and (font_size> file_font_size_mode or upper) and 5<len(head_check_text.strip())<80:                    \n",
    "                        if criteria_check(head_check_text,language) and not cond_head_found:\n",
    "#                             print(int(pagenum),'COND PAGE')\n",
    "#                             print(span_position==0,(bold or font_size>= file_font_size_mode +2 ), (font_size> file_font_size_mode or upper), 5<len(head_check_text.strip())<80)\n",
    "                            cond_head_found=True\n",
    "                            cond_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "                            cond_First_category=True\n",
    "                            cond_second_category=False\n",
    "                            cond_single_page_head_found=True\n",
    "#                             print('FOUND Heading for condition...',span.text)\n",
    "                            \n",
    "                        elif ((font_size,font_family,bold,upper,bullet)==cond_header_match_object or font_size>cond_header_match_object[0] ) and not criteria_check(head_check_text,language)  and cond_head_found:\n",
    "                            cond_head_found=False\n",
    "                            cond_single_page_head_found=True\n",
    "\n",
    "                    cond_words_title=[word.istitle() for word in head_check_text.split() if stopword_check(word,head_check_text,language) and not word.isdigit() ]\n",
    "                    if span_position==0 and all(cond_words_title) and head_check_text.strip() not in definitions and  (len(words_title) >1 or underlined_text )and 5<len(head_check_text.strip())<80 :\n",
    "#                         print('MMMMMMMMARARARA',span.text)\n",
    "\n",
    "                        if criteria_check(head_check_text,language) and  not cond_head_found:\n",
    "                            cond_head_found=True\n",
    "                            cond_second_category=True\n",
    "                            cond_First_category=False\n",
    "                            cond_single_page_head_found=True\n",
    "                            cond_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "#                             print(\"FOUND Condition heading type2 ....\",span.text)\n",
    "                        elif cond_head_found and not criteria_check(head_check_text,language) and cond_second_category and ((font_size,font_family,bold,upper,bullet)==cond_header_match_object or font_size > cond_header_match_object[0] ) :\n",
    "                            cond_head_found=False\n",
    "                            cond_second_category=False\n",
    "                            cond_single_page_head_found=True\n",
    "#                             print('FOUND Condition closure type 2',span.text)\n",
    "\n",
    "                    if cond_head_found==True:\n",
    "                        condition_text=condition_text+' '+span.text\n",
    "                            \n",
    "                    #EXTENSIONS\n",
    "                    if  span_position==0 and (bold or font_size>= file_font_size_mode +2 ) and (font_size> file_font_size_mode or upper) and 5<len(head_check_text.strip())<80:                    \n",
    "                        if ext_check(head_check_text,language) and not ext_head_found: \n",
    "                            ext_head_found=True\n",
    "                            ext_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "                            ext_First_category=True\n",
    "                            ext_second_category=False\n",
    "                            ext_single_page_head_found=True\n",
    "#                             print('FOUND Extension Heading for ext...',span.text)\n",
    "                    \n",
    "                        elif ((font_size,font_family,bold,upper,bullet)==ext_header_match_object or font_size>ext_header_match_object[0] ) and not ext_check(head_check_text,language)  and ext_head_found:\n",
    "                            ext_head_found=False\n",
    "                            ext_single_page_head_found=True\n",
    "#                             print('FOUND Extension Closure for ext ...',span.text)\n",
    "                \n",
    "                    \n",
    "                    ext_words_title=[word.istitle() for word in head_check_text.split() if stopword_check(word,head_check_text,language) and not word.isdigit() ]\n",
    "                    if span_position==0 and all(ext_words_title) and head_check_text.strip() not in definitions and  (len(words_title) >1 or underlined_text )and 5<len(head_check_text.strip())<80 :\n",
    "#                         print('MMMMMMMMARARARA',span.text)\n",
    "\n",
    "                        if ext_check(head_check_text,language) and  not ext_head_found:\n",
    "                            ext_head_found=True\n",
    "                            ext_second_category=True\n",
    "                            ext_First_category=False\n",
    "                            ext_single_page_head_found=True\n",
    "                            ext_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "#                             print(\"FOUND Extension heading type2 ext....\",span.text)\n",
    "                        elif ext_head_found and not ext_check(head_check_text,language) and ext_second_category and ((font_size,font_family,bold,upper,bullet)==ext_header_match_object or font_size > ext_header_match_object[0] ) :\n",
    "                            ext_head_found=False\n",
    "                            ext_second_category=False\n",
    "                            ext_single_page_head_found=True\n",
    "#                             print('FOUND Extension closure type 2 ext',span.text)\n",
    "# \n",
    "                    if ext_head_found==True:\n",
    "                        ext_text=ext_text+' '+span.text\n",
    "                    \n",
    "                #ENDORSEMENTS\n",
    "                    if  span_position==0 and (bold or font_size>= file_font_size_mode +2 ) and (font_size> file_font_size_mode or upper) and 5<len(head_check_text.strip())<80:                    \n",
    "                        if endorsement_check(head_check_text,language) and not endorsement_head_found: \n",
    "                            endorsement_head_found=True\n",
    "                            endorsement_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "                            endorsement_First_category=True\n",
    "                            endorsement_second_category=False\n",
    "                            endorsement_single_page_head_found=True\n",
    "                            print('FOUND Endorsement Heading for ext...',span.text)\n",
    "                    \n",
    "                        elif ((font_size,font_family,bold,upper,bullet)==endorsement_header_match_object or font_size>endorsement_header_match_object[0] ) and not endorsement_check(head_check_text,language)  and endorsement_head_found:\n",
    "                            endorsement_head_found=False\n",
    "                            endorsement_single_page_head_found=True\n",
    "                            print('FOUND Endorsement Closure for ext ...',span.text)\n",
    "                \n",
    "                    \n",
    "                    endorsement_words_title=[word.istitle() for word in head_check_text.split() if stopword_check(word,head_check_text,language) and not word.isdigit() ]\n",
    "                    if span_position==0 and head_check_text.strip() not in definitions and  (len(words_title) >1 or boxed_text) and 5<len(head_check_text.strip())<80 :\n",
    "#                         print('MMMMMMMMARARARA',span.text)\n",
    "                        if endorsement_check(head_check_text,language):                           \n",
    "                                endorsement_y_cord=y_cord\n",
    "                        if endorsement_check(head_check_text,language) and  not endorsement_head_found:\n",
    "                            endorsement_head_found=True       \n",
    "                            endorsement_second_category=True\n",
    "                            endorsement_First_category=False\n",
    "                            endorsement_single_page_head_found=True\n",
    "                            endorsement_header_match_object=(font_size,font_family,bold,upper,bullet,boxed_text)\n",
    "                            print(\"FOUND Endorsement heading type2 ext....\",span.text)\n",
    "                            print(endorsement_header_match_object)\n",
    "                        elif (y_cord-endorsement_y_cord>50) and (endorsement_head_found and not endorsement_check(head_check_text,language) and endorsement_second_category and ((font_size,font_family,bold,upper,bullet,boxed_text)==endorsement_header_match_object or font_size > endorsement_header_match_object[0]) ) :\n",
    "                            endorsement_head_found=False\n",
    "                            print(endorsement_header_match_object,y_cord,endorsement_y_cord,y_cord-endorsement_y_cord)\n",
    "                            endorsement_second_category=False\n",
    "                            endorsement_single_page_head_found=True\n",
    "                            print('FOUND Endorsement closure type 2 ext',span.text)\n",
    "# \n",
    "                    if endorsement_head_found==True:\n",
    "                        endorsement_text=endorsement_text+' '+span.text\n",
    "    #                     else:\n",
    "                    \n",
    "                    \n",
    "                    #INSURING AGREEMENTS\n",
    "                    if  span_position==0 and (bold or font_size>= file_font_size_mode +2 ) and (font_size> file_font_size_mode or upper) and 5<len(head_check_text.strip())<80:                    \n",
    "                        if ins_agg_check(head_check_text,language) and not ins_agg_head_found and not head_found and not ext_head_found and not cond_head_found: \n",
    "                            ins_agg_head_found=True\n",
    "                            ins_agg_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "                            ins_agg_First_category=True\n",
    "                            ins_agg_second_category=False\n",
    "                            ins_agg_single_page_head_found=True\n",
    "#                             print('FOUND INS AGG Heading for ext...',span.text)\n",
    "                    \n",
    "                        elif ins_agg_head_found and not ins_agg_check(head_check_text,language):\n",
    "                            ins_agg_head_found=False\n",
    "                            ins_agg_single_page_head_found=True\n",
    "#                             print('FOUND INS AGG Closure for ext ...',span.text)\n",
    "                \n",
    "                    \n",
    "                    ins_agg_words_title=[word.istitle() for word in head_check_text.split() if stopword_check(word,head_check_text,language) and not word.isdigit() ]\n",
    "                    if span_position==0 and all(ins_agg_words_title) and head_check_text.strip() not in definitions and  (len(words_title) >1 or underlined_text )and 5<len(head_check_text.strip())<60 :\n",
    "                        if ins_agg_check(head_check_text,language) and  not ins_agg_head_found and not head_found and not cond_head_found and not ext_head_found:\n",
    "                            ins_agg_head_found=True\n",
    "                            ins_agg_second_category=True\n",
    "                            ins_agg_First_category=False\n",
    "                            ins_agg_single_page_head_found=True\n",
    "                            ins_agg_header_match_object=(font_size,font_family,bold,upper,bullet)\n",
    "#                             print(\"FOUND INS AGG heading type2 ext....\",span.text)\n",
    "                        elif ins_agg_head_found and not ins_agg_check(head_check_text,language):\n",
    "                            ins_agg_head_found=False\n",
    "                            ins_agg_second_category=False\n",
    "                            ins_agg_single_page_head_found=True\n",
    "#                             print('FOUND INS AGG closure type 2 ext',span.text)\n",
    "# \n",
    "                    if ins_agg_head_found==True:\n",
    "                        ins_agg_text=ins_agg_text+' '+span.text\n",
    "###############################             \n",
    "                        \n",
    "                    if font_size_match:\n",
    "                        if font_size<=file_font_size_mode-1:\n",
    "                            text_lis.append(' ')\n",
    "                    text=span.text\n",
    "                    text_plain=text\n",
    "                   \n",
    "                    for term in def_terms:\n",
    "                        if term.lower().strip() in text.lower() and definitions[term][0].strip() not in text and term not in sub_definitions_in_page:\n",
    "#                             def_page.append(definitions[term])\n",
    "#                             print(pagenum)\n",
    "                            src_str  = re.compile(re.escape(term), re.IGNORECASE)\n",
    "                            text=src_str.sub('###{}@@{}%%%'.format(term,definitions[term][0]),text)\n",
    "#                             print(text,'\\n',term,'TERM!!!!@#$%^&*&^%#$%^&')\n",
    "                            sub_definitions_in_page.append(term)\n",
    "                            sub_page_def_list.append({'name':term,'text':definitions[term][0]})\n",
    "#                             print(definitions_in_page)\n",
    "                            break\n",
    "#                     print(definitions_in_page)\n",
    "\n",
    "                    \n",
    "                    text_lis.append(text)\n",
    "                    text_plain_lis.append(text_plain)\n",
    "                    span_text_pos+=len(text_plain)\n",
    "                    previous_span=span\n",
    "                    \n",
    "\n",
    "            if text_lis:\n",
    "                if(int(pagenum) in [1,2]) and 'wording' in file:\n",
    "                    continue\n",
    "\n",
    "                text_lis=text_lis[:-1]\n",
    "                text_para=''.join(text_lis)\n",
    "                text_plain_lis=text_plain_lis[:-1]\n",
    "                text_plain_para=''.join(text_plain_lis)\n",
    "#                 print(len(re.findall('\\d',text_para))>20,'content' in text_para,int(pagenum))\n",
    "                if(len(re.findall('\\.',text_para))>(len(text_para)/3) or (len(re.findall('\\d',text_para))>50 and 'gbp' not in text_para.lower() and 'content' in text_para.lower())) : # and int(pagenum)<=2\n",
    "#                     print('PASS')\n",
    "                    text_para,text_plain_para=' ',' '\n",
    "                    text_lis,text_plain_lis=[],[]\n",
    "                    single_page_head_found=False\n",
    "                    head_found=False\n",
    "                    cond_head_found=False\n",
    "                    ext_head_found=False\n",
    "                    endorsement_head_found=False\n",
    "                    continue\n",
    "                else:\n",
    "                    bold_lis=clean_pharses(bold_lis)\n",
    "                    if pagenum in page_list and pagenum!='1':\n",
    "                        pagenum=int(pagenum)+1\n",
    "                    excl_flag,excl_count,excl_pos_lis=excl_extract(text_plain_lis,language)\n",
    "                    cond_flag,cond_count,cond_pos_lis=cond_extract(text_plain_lis,language)\n",
    "                    ext_flag,ext_count,ext_pos_lis=ext_extract(text_plain_lis,language)\n",
    "                    if int(pagenum)==1:\n",
    "                        if head_found or single_page_head_found or excl_count>0:\n",
    "#                             print(pagenum,True,'!!!',excl_count)\n",
    "                            excl_flag=True\n",
    "                        else:\n",
    "                            excl_flag=False\n",
    "                    else:\n",
    "                        if head_found or single_page_head_found:\n",
    "#                             print(pagenum,True,'!!!')\n",
    "                            excl_flag=True\n",
    "#                             print(excl_flag,'EXCL')\n",
    "                        else:\n",
    "                            print(pagenum,excl_flag,'\\n')\n",
    "                    #####################\n",
    "                    if cond_head_found or cond_single_page_head_found or cond_count>0:\n",
    "                        cond_flag=True\n",
    "#                         print('COND','TRUE')\n",
    "                    else:\n",
    "                        cond_flag=False\n",
    "                    \n",
    "                    if ext_head_found or ext_single_page_head_found or ext_count>0:\n",
    "                        ext_flag=True\n",
    "#                         print('EXT','TRUE',pagenum)\n",
    "                    else:\n",
    "#                         print('EXT','FALSE',pagenum)\n",
    "                        ext_flag=False\n",
    "                    if endorsement_head_found or endorsement_single_page_head_found:\n",
    "                        endorsement_flag=True\n",
    "                        print(pagenum,endorsement_flag)\n",
    "                    else:\n",
    "                        endorsement_flag=False\n",
    "                        print(pagenum,endorsement_flag)\n",
    "                    if ins_agg_head_found or ins_agg_single_page_head_found:\n",
    "                        ins_agg_flag=True\n",
    "#                         print(pagenum)\n",
    "                    else:\n",
    "#                         print(pagenum)\n",
    "                        ins_agg_flag=False\n",
    "\n",
    "                    for term,defs in definitions.items():\n",
    "                        if defs[1]==pagenum:  ###defs[1] is the pagenumber\n",
    "                            definition_text=definition_text+'          '+term+' '+defs[0]\n",
    "                            def_in_page.append({'name':term,'text':defs[0]})        \n",
    "#                     print(definition_text)\n",
    "                    print(pagenum,definition_text)\n",
    "                    if definition_text:\n",
    "                        def_flag=True\n",
    "\n",
    "                    if def_flag:\n",
    "                        def_search_flag=True\n",
    "#                         print('DEF','TRUE')\n",
    "                    else:\n",
    "                        def_search_flag=False\n",
    "#                         print('DEF','FALSE')\n",
    "                    \n",
    "                    if pg_no>2:\n",
    "                        endorsements=False\n",
    "                    else:\n",
    "                        endorsements=True\n",
    "                    print('PAGE',pagenum)        \n",
    "                    if text_para in local_indexed.keys():\n",
    "                        text_para=text_para+' '\n",
    "                    local_indexed[text_para]=(file,pagenum,bold_lis,text_plain_para,excl_flag,excl_count,excl_pos_lis,subdir,sub_page_def_list,country,language,definition_text,def_search_flag,endorsements,excl_text,condition_text,cond_flag,cond_count,cond_pos_lis,def_in_page,ext_text,ext_flag,ext_count,ext_pos_lis,span_text_pos,header_pos,endorsement_flag,endorsement_text,ins_agg_flag,ins_agg_text)\n",
    "#                     print(sub_page_def_list,'DEF LIST!!!!!1')\n",
    "                    sub_page_def_list=[]\n",
    "                    span_text_pos=0\n",
    "                    header_pos=[]\n",
    "                    text_para,text_plain_para='','' \n",
    "                    text_plain_lis,text_lis,bold_lis=[],[],[]\n",
    "                    definition_text=''\n",
    "                    single_page_head_found=False\n",
    "                    cond_single_page_head_found=False\n",
    "                    ext_single_page_head_found=False\n",
    "                    endorsement_single_page_head_found=False\n",
    "                    ins_agg_single_page_head_found=False\n",
    "                    condition_text=''\n",
    "                    ext_text=''\n",
    "                    excl_text=''\n",
    "                    ins_agg_text=''\n",
    "                    endorsement_text=''\n",
    "                    def_in_page=[]\n",
    "                    def_flag=False\n",
    "    return(local_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_pdf_path(path):\n",
    "    file_list=os.listdir(path)\n",
    "    for file in file_list:\n",
    "        raw_filename=file[:file.rfind(\".\")]\n",
    "        pdf_filename=raw_filename+'.pdf'\n",
    "#         print(raw_filename,pdf_filename,'FILE!!')\n",
    "        if pdf_filename in file_list:\n",
    "            print('continued!!!!!!!!!!!!!')\n",
    "            continue\n",
    "        if file.endswith('doc') or file.endswith('docx'):\n",
    "            print('processing!!!')\n",
    "            wordToPdf(os.path.join(path,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootDir='V://COG//AU- Property//'\n",
    "# for dirname,subdirlist,filelist in os.walk(rootDir):\n",
    "#     print(dirname)\n",
    "#     for subdir in subdirlist:\n",
    "#         path=os.path.join(dirname,subdir)\n",
    "# #         doc_pdf_path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints SUBDIR!!!!!!!!!!!!!\n",
      "Broker Wording SUBDIR!!!!!!!!!!!!!\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A.pdf\n",
      "1 False\n",
      "PASS\n",
      "3 False\n",
      "4 False\n",
      "5 False\n",
      "6 False\n",
      "7 False\n",
      "8 False\n",
      "9 False\n",
      "10 False\n",
      "11 False\n",
      "12 False\n",
      "13 False\n",
      "14 False\n",
      "15 False\n",
      "16 False\n",
      "FOUND Endorsement heading type2 ext.... Additional terms and conditions \n",
      "\n",
      "(9, '', True, False, False, True)\n",
      "17 True\n",
      "18 True\n",
      "(9, '', True, False, False, True) 16168 14385 1783\n",
      "FOUND Endorsement closure type 2 ext Data Protection \n",
      "\n",
      "19 True\n",
      "20 False\n",
      "21 False\n",
      "22 False\n",
      "23 False\n",
      "24 False\n",
      "25 False\n",
      "26 False\n",
      "27 False\n",
      "28 False\n",
      "29 False\n",
      "30 False\n",
      "31 False\n",
      "32 False\n",
      "33 False\n",
      "34 False\n",
      "35 False\n",
      "36 False\n",
      "37 False\n",
      "38 False\n",
      "39 False\n",
      "40 False\n",
      "41 False\n",
      "42 False\n",
      "43 False\n",
      "44 False\n",
      "45 False\n",
      "46 False\n",
      "47 False\n",
      "48 False\n",
      "49 False\n",
      "50 False\n",
      "51 False\n",
      "52 False\n",
      "53 False\n",
      "54 False\n",
      "55 False\n",
      "56 False\n",
      "57 False\n",
      "58 False\n",
      "59 False\n",
      "60 False\n",
      "61 False\n",
      "62 False\n",
      "63 False\n",
      "64 False\n",
      "65 False\n",
      "66 False\n",
      "67 False\n",
      "68 False\n",
      "69 False\n",
      "70 False\n",
      "71 False\n",
      "72 False\n",
      "73 False\n",
      "74 False\n",
      "75 False\n",
      "76 False\n",
      "77 False\n",
      "78 False\n",
      "79 False\n",
      "80 False\n",
      "81 False\n",
      "82 False\n",
      "83 False\n",
      "84 False\n",
      "85 False\n",
      "86 False\n",
      "87 False\n",
      "88 False\n",
      "89 False\n",
      "90 False\n",
      "91 False\n",
      "92 False\n",
      "93 False\n",
      "94 False\n",
      "PASS\n",
      "96 False\n",
      "97 False\n",
      "98 False\n",
      "99 False\n",
      "100 False\n",
      "101 False\n",
      "102 False\n",
      "103 False\n",
      "104 False\n",
      "105 False\n",
      "106 False\n",
      "107 False\n",
      "108 False\n",
      "109 False\n",
      "110 False\n",
      "111 False\n",
      "112 False\n",
      "113 False\n",
      "114 False\n",
      "115 False\n",
      "115 \n",
      "PAGE 115\n",
      ".ipynb_checkpoints SUBDIR!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "rootDir='test/tes/'\n",
    "country='uk'\n",
    "local_indexed={}\n",
    "language='english'\n",
    "if 'spanish' in rootDir:\n",
    "    language='spanish'\n",
    "for dirname,subdirlist,filelist in os.walk(rootDir):\n",
    "    for subdir in subdirlist:\n",
    "        print(subdir, 'SUBDIR!!!!!!!!!!!!!')\n",
    "        path=os.path.join(dirname,subdir)    \n",
    "        local_indexed_subdir=create_local_index(path,subdir,language,country)\n",
    "        local_indexed.update(local_indexed_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-29-c7d7881669f4>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-c7d7881669f4>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    doc = fitz.open('V:\\COG\\TRACK AND TRACE\\Data\\Documents\\MasterPackage\\')\u001b[0m\n\u001b[1;37m                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import random\n",
    "doc_text=\"\"\n",
    "doc = fitz.open('V:\\COG\\TRACK AND TRACE\\Data\\Documents\\MasterPackage\\')\n",
    "for page in doc:\n",
    "    doc_text= page.getText(\"text\")+\"\\n\"\n",
    "    print(doc_text.find('Costa Rica'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(local_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "\n",
    "cosmo_endpoint=\"https://nf-poc-cdb-sql.documents.azure.com\"\n",
    "cosmo_key=\"iEcEfrxYe0Fm9QtoxDrOpLvGsfzjowwybULlWT9Uz4XxV4RmOIAnRuLdgRFUu1LPU5Vwk3UGivRrPrxnk7083w==\"\n",
    "client = CosmosClient(cosmo_endpoint, cosmo_key)\n",
    "database=client.get_database_client('policy-analysis')\n",
    "container=database.get_container_client('tt_documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 1 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 3 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 4 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 5           no_name_found means premises , anywhere within the Territorial Limits,  owned, leased or occupied by the Insured for the purpose of the Business\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 6 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 7 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 8 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 9 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 10 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 11 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 14 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 15 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 16 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 17           As used herein, a Communicable Disease means any    physical distress, illness, or disease caused or transmitted directly or indirectly by any virus, bacterium,  parasite or other organism or any variation thereof, whether deemed living or not, and regardless of the  means of transmission  or    any virus, bacterium, parasite or other organism or any variation thereof, whether deemed living or not,  which is capable of causing physical distress, illness or disease        This Endorsement applies to all coverage Extensions, additional coverages, exceptions to any Exclusion and other  coverage grant      All other terms, Conditions and Exclusions of the Policy remain the same        Restrictions on the Use of the Premises    The Restrictions on the Use of the Premises Extension to Section 2 Business Interruption of this Policy is deleted and  replaced by the following   Section 2 Business Interruption of this Policy is extended to include loss resulting from interruption of or interference with  the Business carried on by the Insured at the Premises in consequence of    the discovery of vermin or pests at the Premises  or any accident causing defects in the drains or other sanitary arrangements at the Premises   which causes restrictions on the use of the Premises on the order or advice of the competent local authority  or any occurrence of murder or suicide at the Premises   which shall be deemed to be loss resulting from Damage  to property used by the Insured at the  Premises   provided that -  the Company shall not be liable for the first 24 hours of any interruption of or interference with the Business   the Company shall only be liable for the loss arising at those Premises which are directly affected by the occurrence,  discovery or accident   iii   the Company shall not be liable under this Extension for any costs incurred in the cleaning, repair, replacement, recall  or checking of property   the liability of the Company under this Extension in respect of all Occurrences happening during the Period of  Insurance shall not exceed the sum stated in the Schedule  For the purposes of this Extension          -  a  Indemnity Period means the period during which the results of the Business shall be affected in consequence of the  Damage, beginning with the date from which the restrictions on the Premises are applied (or in the case of c above,  with the date of the occurrence) and ending not later than the Maximum Indemnity Period thereafter          b  Maximum Indemnity Period means three  months          c  Premises means only those locations stated in the Premises definition in Sections 1 and 2 in the event that the Policy  includes an extension which deems Damage at other locations to be Damage at the Premises such extension shall not  apply to this Extension          - Indemnity Period means the period during which the results of the Business shall be affected in consequence of the  Damage, beginning with the date from which the restrictions on the Premises are applied  and ending not later than the Maximum Indemnity Period thereafter          Maximum Indemnity Period means three  months\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 18 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 19 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 20 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 21 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 22 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 23           Collections means any Fine Art, including frames, shadowboxes and glasses used in the actual display of the items          Collections of Others means Collections not owned by the Insured, but in its care, custody, or control or related to the  Scheduled Collections, cover is provided on a wall to wall basis if the loan agreement so requires          This means that cover  is provided from the time the items are removed in preparation for shipment from the place where they are normally kept  until they are returned          Scheduled Collections means Collections which are individually listed with an assigned value as set out in the  Schedule or on file with the Company          Unscheduled Collections means Collections which are not individually set out in the Schedule or on file with the  Company, but are similar in nature, or related to the Scheduled Collection of the Insured     Property not otherwise provided for  In respect of any other property not otherwise provided for - the cost of  the rebuilding or replacement of such lost or destroyed property, which provided that the Company’s liability is not  thereby increased may be carried out on the same or another site and in any manner suitable to the requirements of the  Insured, or the repair or restoration of such damaged property  in either case to a condition equivalent to or substantially the same as but not better or more extensive than its condition  when new  provided that   no payment beyond the value of the property at the time of its loss, destruction or damage shall be made  unless reinstatement commences and proceeds without unreasonable delay until the cost of reinstatement shall have been actually incurred  if any such property is lost, damaged or destroyed in part only, the Company’s liability shall not exceed the sum  representing the cost which the Company could have been called upon to pay for reinstatement if such property  had been wholly destroyed   Where certain Property Insured is leased to the Insured the basis of valuation in the event of loss, destruction or  damage will be the higher of that determined above or the termination sums as detailed by the terms of any leasing  agreement\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 24           a)  Requirements means the stipulations of          Requirements means the stipulations of    European Union legislation (as enacted in applicable national law\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 25 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 26           Breakdown means the failure, distortion, breaking or burning out of any part of property whilst in use, arising from either   mechanical or electrical defects in the item of property  or  failure or fluctuation of the electricity supply\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 41 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 42           Rent Payable means the periodic payments made by the Insured for the lease of buildings not belonging to the Insured  which do not cease, representing the amount of rent which continues to be payable by the Insured for buildings occupied but  not owned by the Insured in respect of such building or any part thereof which are unfit for occupation in consequence of its  Damage, subject to the Company’s liability being limited to the          Rent Receivable means the periodic payments made to the Insured for the lease/sublease of buildings (including but not  limited to the described Premises) belonging to or leased by but not necessarily occupied by the Insured, if the said building  or any part thereof is unfit for occupation in consequence of its Damage\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 43           Outstanding Debit Balances means the total amount outstanding in Customers’ accounts as set out in the Insured’s  accounts as at the end of the financial period immediately preceding the Damage, adjusted for  bad debts  amounts debited  and credited  to Customers’ accounts in the period between the end of such financial period and the date of  the Damage  and any abnormal condition of trade which had or could have had a material effect on the Business   so that the figures thus adjusted shall represent as nearly as may be reasonably practicable those which would have been  obtained at the date of the Damage had such Damage not occurred     Research Establishment Expenditure  Research Establishment Expenditure applies to the loss sustained by the Insured in consequence of the Damage  in respect of the Research Establishment Expenditure and increase in cost of working, and the  amount shall be calculated by   in respect of Research Establishment Expenditure  for each working week in the Indemnity Period during which  the activities of the Business are, in consequence of the Damage   totally interrupted or totally given over to the re working of projects affected by the Damage the Insured  Amount Per Week    partially interrupted or partially given over to the re working of projects affected by the Damage an equitable  proportion of the Insured Amount Per Week based upon the time rendered ineffective by reason of the  Damage  and in respect of increase in cost of working  the additional expenditure reasonably and necessarily incurred solely in  consequence of the Damage in order to minimise the interruption but the amount payable under this heading shall not  exceed the additional amount that would have been payable under paragraph a above for loss of Research  Establishment Expenditure if no such increase in cost of working had been incurred  adding any reduction in   the amount of grants, endowments and other financial  contributions made to the Insured pursuant to written agreements,  in effect at the inception of this Policy, to further Research and Development Operations, provided that the  Insured   reports the value of such agreements to the Company prior to the inception of this Policy   reports the value of any agreements executed after inception of this Policy within ninety  days of their  execution    iii   reports any amendment to such agreements that change the value of such agreements within ninety  days of  the execution of such amendments  and   continues the Research and Development Operations   less any sum saved during the Indemnity Period in respect of such Research Establishment Expenditure as may cease  or be reduced in consequence of the Damage    For the purposes of this Clause          Research Establishment Expenditure means the total expenditure on   research by the Insured at the described Premises less the relative cost of raw materials consumed  or Research and Development Operations by the Insured at the described Premises less the relative cost of raw  materials consumed, income derived from research undertaken under contract by the Insured on behalf of Customers  and financing transactions          Insured Amount Per Week means one fifty-second part of the Research Establishment Expenditure incurred during  the financial year immediately before the date of the Damage   allowing for the Trend in the Business\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 44           a  Rate of Gross Profit means the rate of Gross Profit that would have been earned on the Turnover during the  Indemnity Period but for the Damage          b  Standard Turnover means the Turnover which but for the Damage (as defined within Section 2 Business  Interruption of this Policy) would have been earned during the Indemnity Period          c  Indemnity Period means the period beginning with the date upon which, but for the Damage, Turnover would  have commenced and ending not later than the Maximum Indemnity Period thereafter during which the results of  the Business shall be affected in consequence of the Damage          Indemnity Period means the period beginning with the date upon which, but for the Damage, Turnover would  have commenced and ending not later than the Maximum Indemnity Period thereafter during which the results of  the Business shall be affected in consequence of the Damage     Breakdown of Computer Equipment  notwithstanding anything contained in Excluded Causes Exclusion h of combined Sections 1 and 2 of this Policy to the  contrary, for loss resulting from interruption of or interference with the Business in consequence of Damage  to Computer Equipment following Computer Breakdown     Breakdown of all other Machinery, Plant and Contents  notwithstanding anything contained in Excluded Causes Exclusion i of combined Sections 1 and 2 of this Policy to the  contrary, for loss resulting from interruption of or interference with the Business in consequence of Damage  to all other machinery, plant and contents  caused by the Breakdown thereof Breakdown\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 52 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 53           Buildings means buildings at the described Premises including landlords’ fixtures and fittings, fixed glass , foundations, walls, gates, fences, car parks, outbuildings, yards,  swimming pools, pavements, drains, sewers, piping, cabling, wiring and associated control equipment and accessories only  to the extent of the Insured’s responsibility and liability          Computer Breakdown means the actual breaking, distortion or electrical burnout of any item of Computer Equipment or part thereof whilst in  use at the described Premises, causing stoppage of its normal function and requiring its repair or replacement before  normal operating conditions prevail          Computer Equipment means  the computer equipment  used for  the electronic processing communication and storage of data, but excluding any such equipment controlling any  manufacturing process  and/or  ancillary equipment solely for the use with computer equipment comprising air conditioning equipment, generating  equipment, uninterruptable power supply and voltage regulation equipment, temperature and humidity recording  equipment, electronic access equipment, heat, smoke and water detection equipment, lightning and transient  overvoltage protection devices   owned by or for which the Insured is legally liable          Computer Virus means a set of corrupting, harmful or otherwise unauthorised instructions or code including a set of maliciously introduced  unauthorised instructions or code, programmatic or otherwise, that propagate themselves through a computer system or  network of whatsoever nature  Computer Virus includes but is not limited to ‘trojan horses’, ‘worms’ and ‘time or logic  bombs’          Contents means machinery, plant and all other contents of Buildings  including but not limited to  tenants’ improvements, alterations and decorations  fixtures and fittings  and trade utensils  Valuable Papers  patterns, models, moulds, plans and designs  Computer Equipment   Electronic Data processing media   Mobile Communication Property  and  so far as they are not otherwise insured employees’, directors’ and visitors’ personal effects of every description  for an amount not  exceeding the amount shown in the Schedule   at the described Premises, owned by or for which the Insured is legally liable but excluding property more specifically  insured\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 61           Applicable Sections means Section 1 Property Damage and Section 2 Business Interruption\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 65 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 71 \n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 91           Military Authority shall mean a military or security authority operating on behalf of a state recognised by the United  Nations\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 93           Occurrence means any one loss and/or series of losses arising out of and directly occasioned by any one Insured Peril or series of  Insured Perils for the same purpose or cause  The duration and extent of any one “Occurrence” shall be limited to all  losses sustained by the Insured at the Property Insured herein during any period of   seventy two  consecutive hours arising out of the same purpose or cause in respect of   Act of Terrorism and/or Sabotage and/or  Riots, Strikes, Civil Commotion and/or Malicious Damage    thirty  consecutive days arising out of the same purpose or cause in respect of   Insurrection, Revolution or Rebellion and/or  Mutiny and/or Coup d’Etat and/or  iii   War and/or Civil War   However no such period of seventy two  consecutive hours or thirty  consecutive days  may extend  beyond the expiration of this Section unless the Insured shall first sustain direct physical damage by any one Insured  Peril or series of Insured Perils prior to expiration and within such period of nor shall any period of seventy two   consecutive hours or thirty  consecutive days  commence prior to the attachment of this Section          Malicious Damage means physical loss, destruction or damage of property caused by the actions of anyone intending to cause harm or mischief  during the disturbance of the public peace          Insurrection means a violent uprising of citizens in resistance to their government          Revolution means the overthrow of a regime or political system by its citizens          Rebellion means a deliberate, organised and open resistance by force of arms to the laws or operations of a government as committed  by its citizens or subjects          Mutiny means a wilful resistance by members of legally armed or peace keeping forces to a superior officer          Coup d’Etat means the sudden, violent and illegal overthrow of a sovereign government          Civil War means a hostile contention by armed forces carried on between opposing citizens or subjects of the same country or nation          War means declared or undeclared hostile action between two or more nations or states          Listed Territories means the territories stated as such in the Schedule\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 94           Electronic Data    electronic means including but not limited to computer hacking or the introduction of any form of computer virus or  corrupting or unauthorised instructions or code or the use of any electromagnetic weapon   This Exclusion shall not operate to exclude losses  arising from the  use of any computer, computer system or computer software program or any other electronic system in the launch and/or  guidance system and/or firing mechanism of any weapon or missile      Hoax  loss or increased cost as a result of threat or hoax     Looting and Pillaging and/or Other Theft loss or damage caused by or arising out the Looting and Pillaging of the Property Insured hereunder or caused by  any person taking part in any such activity, other than where this is a direct result of an Insured Peril and occurs  within 24 hours of the commencement of this          For the purpose of this Exclusion means plundering and stealing in a time of unrest  loss or damage caused by or arising out of burglary, house-breaking, theft or larceny, vandalism, criminal damage or  activity, mysterious or unexplained disappearance of Property Insured hereunder or directly or indirectly caused by\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 106           Company means Chubb European Group SE          Earthquake means earth movement due to a natural seismic disturbance caused by a sudden movement of the earth’s crust and  including      loss, destruction or damage from Earthquake Shock  subsequent  loss, destruction or damage caused by fire or explosion resulting therefrom  and the eruption explosion or effusion of a volcano   but excluding Flood          Earthquake Shock means     earthquake shock excluding any subsequent loss, destruction or damage or caused by fire or explosion resulting  therefrom  and     volcanic eruption meaning the eruption explosion or effusion of a volcano   but excluding Flood     Earthquake          Designated Earthquake Areas means  Canada  all of Canada    Caribbean Region  the islands comprising the whole of Cuba, Haiti, the Dominican Republic, Jamaica, Puerto  Rico, all islands comprising the Commonwealth of the Bahamas, the Cayman Islands, the  Turks and Caicos Islands, the British Virgin Islands, the United States Virgin Islands, the  Federation of St  Kitts and Nevis, Antigua and Barbuda, the Department of Guadeloupe, the  Commonwealth of Dominica, the Department of Martinique and St  Vincent and the  Grenadines and the islands of Anguilla, Barbados, Grenada, Montserrat, St  Lucia and St  Martin  the Netherlands Antilles, Trinidad and Tobago    North America  Mexico  Africa  Algeria, Burundi, Democratic Republic of Congo, Djibouti, Egypt, Ethiopia, Kenya, Lesotho,  Malawi, Morocco, Mozambique, Nigeria, Rwanda, Republic of South Africa, Tanzania,  Tunisia, Uganda, Zambia    Asia  Armenia, Azerbaijan, Bangladesh, Bhutan,  China, Georgia, India, Indonesia, Israel, Jordan,  Kazakhstan, Kyrgyzstan, Lebanon, Mongolia, Nepal, Pakistan, Palestine, Philippines, Saudi  Arabia, Taiwan, Tajikistan, Thailand, Turkmenistan, Uzbekistan, Yemen    Asia /Europe  Russia, Turkey    Central America  Belize, Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, Panama\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 107           Excluded Territories means Afghanistan, Angola, the territory of Crimea, Cuba, Guinea-Bissau, Guyana, Iran, Iraq, Liberia, Libya, Myanmar,  North Korea, Sierra Leone, North Sudan, South Sudan, Syria, Tibet and Yemen          Flood means the escape of water from its normal, natural or artificial confines  or  inundation from the sea including tidal wave or tsunami\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 108           Limit of Liability means the applicable amount shown in the Schedule, Sections, Endorsements and Extensions in which they appear\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 109           Property Insured means the property shown as such in the Schedule          Storm means storm, windstorm, hurricane, tornado, tempest and typhoon including subsequent loss, destruction or damage  caused by water that backs up from a sewer or drain as a direct result thereof but excluding Flood   In respect of Storm in the United States of America if the Local Policy  refers to the term “Named Windstorm” in relation to this peril, then the  definition of Storm  shall be deemed to “Named Windstorm” as defined within the Local Policy with  respect to the United States of America     Storm          Designated Storm Areas means  Caribbean   Region  the islands comprising the entire islands of Cuba, Haiti, the Dominican Republic, Jamaica,  Puerto Rico  all islands comprising the Commonwealth of the Bahamas, the Cayman  Islands, the Turks and Caicos Islands, the British Virgin Islands, the United States Virgin  Islands, the Federation of St  Kitts and Nevis, Antigua and Barbuda, the Department of  Guadeloupe, the Commonwealth of Dominica, the Department of Martinique and St   Vincent and the Grenadines and the islands of Anguilla, Barbados, Grenada, Montserrat, St   Lucia and St Martin  the Netherlands Antilles, Trinidad and  Tobago    United States of  America - Gulf States  and Eastern Seaboard  Region  the Gulf States and Eastern Seaboard Region defined as the area comprising the entire  State of Florida and all Tier 1 counties, in the States of   Alabama, the counties of Baldwin, Escambia, and Mobile    Connecticut, the counties of Fairfield, New Haven, and New London    Georgia, the counties of Bryan, Camden, Chatham, Glynn, Liberty, and McIntosh    Louisiana, the counties  of Acadia, Ascension, Assumption,  Calcasieu, Cameron, East Baton Rouge, Iberia, Iberville, Jefferson Davis, Jefferson,  Lafayette, Lafourche, Orleans, Plaquemines, St  Bernard, St  Charles, St  James, St  John  The Baptist, St  Martin, St  Mary, St  Tammany, Terrebonne, and Vermillion    Massachusetts, the counties of Barnstable, Bristol, Dukes, Essex, Middlesex, Nantucket,  Norfolk, Plymouth, and Suffolk    Mississippi, the counties of George, Greene, Hancock, Harrison, Jackson, Pearl River, and  Stone    New Jersey, the counties of Atlantic, Monmouth, and Ocean    New York, the counties of Kings, Nassau, Queens, and Suffolk    North Carolina, the counties of Beaufort, Bertie, Brunswick, Camden, Carteret, Chowan,  Columbus, Craven, Currituck, Dare, Hyde, Jones, New Hanover, Onslow, Pamlico,  Pasquotank, Pender, Perquimans, Tyrrell, and Washington    Rhode Island, the counties of Newport, Providence, and Washington\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 110           Sturmflut means flooding in Germany caused by a surge of sea water, either directly onto land or up rivers and then onto land          Sub-Limit of Liability means the applicable amount, which form part of the Limit of Liability and do not apply in addition to it unless  otherwise shown in the Schedule, Sections, Endorsements and Extensions in which they appear          United Kingdom means Great Britain, Northern Ireland, the Isle of Man and the Channel Islands\n",
      "REDACTED_07852D6B-E59F-4DF9-AEA5-2BBFE5CEC60A 111           For the purposes of this General Exclusion means  in respect of England, Wales and Scotland but not the territorial seas adjacent thereto as defined by the Territorial Sea  Act 1987 nor Northern Ireland, the Isle of Man or the Channel Islands   For the purposes of this General Exclusion\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for key,value in local_indexed.items():\n",
    "    doc={}\n",
    "    doc['text']=key\n",
    "    doc['page']=int(value[1])\n",
    "    if value[4]==True or value[0].find('Exclusion')!=-1:\n",
    "        doc['IsExclusion']=True\n",
    "    else:\n",
    "        doc['IsExclusion']=False\n",
    "    doc['doc_name']=value[0].replace('.pdf','')\n",
    "    doc['id']=doc['doc_name']+' '+str(doc['page'])\n",
    "    doc['bold_phrases']=value[2]\n",
    "    doc['plain_text']=value[3]\n",
    "#     print(value[3],'\\n')\n",
    "    doc['excl_count']=value[5]\n",
    "    doc['excl_pos']=value[6]\n",
    "    doc['folder']=value[7]\n",
    "    doc['definitions']=[{'name':key,'text':value} for key,value in re.findall('###(.*?)@@(.*?)%%%',doc['text'])]\n",
    "#     print(doc['definitions'],'\\n\\n\\n')\n",
    "    doc['country']=value[9]\n",
    "    doc['language']=value[10]\n",
    "    doc['definition_text']=value[11]\n",
    "#     print(doc['definition_text'],'\\n\\n')\n",
    "    if doc['definition_text']:\n",
    "        doc['definition_flag']=True\n",
    "    else:\n",
    "        doc['definition_flag']=False\n",
    "    if value[14]==True or 'endorsement' in value[0].lower(): \n",
    "        doc['endorsements']=True\n",
    "    else:\n",
    "        doc['endorsements']=value[13]\n",
    "    doc['excl_text']=value[14]\n",
    "    doc['cond_text']=value[15]\n",
    "    doc['cond_flag']=value[16]\n",
    "    doc['cond_count']=value[17]\n",
    "    doc['cond_pos']=value[18]\n",
    "    doc['definitions_in_page']=value[19]\n",
    "    doc['ext_text']=value[20]\n",
    "    doc['ext_flag']=value[21]\n",
    "    doc['ext_count']=value[22]\n",
    "    doc['ext_pos']=value[23]\n",
    "    doc['span_len']=value[24]\n",
    "    doc['header_pos']=value[25]\n",
    "    doc['endorsement_flag']=value[26]\n",
    "    doc['endorsement_text']=value[27]\n",
    "#     if not doc['excl_text'] and not doc['cond_text'] and not doc['ext_text'] and not doc['definition_text']:\n",
    "    doc['insuring_agreement_flag']=value[28]\n",
    "    doc['insuring_text']=value[29]\n",
    "    doc['effective_from']='{}-09-15T23:14:25.7251173Z'.format(random.randint(1995,2010))\n",
    "    doc['effective_till']='{}-09-15T23:14:25.7251173Z'.format(random.randint(2011,2021))\n",
    "#         print(doc['insuring_agreement_flag'])\n",
    "#     else:\n",
    "#         doc['insuring_agreement_flag']=False\n",
    "#         doc['insuring_text']=''\n",
    "#         print(doc['insuring_agreement_flag'])\n",
    "#     try:       \n",
    "#         container.create_item(body=doc)\n",
    "#     except Exception as err:\n",
    "#         print(\"Exception in clause search!!!!!!!!\",str(err))\n",
    "#         pass\n",
    "#     print(doc['span_len'])\n",
    "    if doc['insuring_agreement_flag']:\n",
    "        print(doc['doc_name'],doc['page'],doc['definition_text'])\n",
    "# #     print(doc['id'],value[1],'EXT ',doc['ext_flag'])\n",
    "# #     if doc['page']==23:\n",
    "#     print(doc['page'],doc['plain_text'].find('Costs, Fees and Expenses'),doc['header_pos'])\n",
    "# #     if doc['page']==22:\n",
    "# #     print(doc['doc_name'],doc['page'],doc['plain_text'],'EXCL!!!!!!!!!!',doc['excl_text'],'\\n\\n\\n\\n\\n\\n')\n",
    "# #     print(doc['doc_name'],doc['page'],'PLAIN TEXT@!!!',doc['plain_text'],'\\n\\nEXCL!!!!!!!!',doc['excl_text'],'\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(local_indexed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
